
Hi everyone, my name is Arvind, and I am in product management at VMware, now Broadcom. Today, I'll talk about some of the solutions we are developing at VMware that relate to memory. So, let me skip.

So, this is just a disclaimer. I'm supposed to show this company policy.

So, today, when we actually look at our customers, what we see is a typical problem with respect to CPU and memory imbalance. So, when customers actually deploy their systems, they provision their memory, they right-size their infrastructure during the purchase time, and they size their VMs. And, they actually calculate the consolidation ratios. When they deploy it, they see that their memory ends up being completely consumed, even though it doesn't fully actually run the workloads, right? So, there are two measures that VMware uses typically. So, one measure is, what's the consumed memory on a host system, right? Consumed memory on the host system typically is around 80-90%. For our customers, they leave a little bit of their memory on the host, just so that things like vMotion, etc., can work. But otherwise, you know, the host memory is consumed. Actually, that might be true for a lot of the other non-VMware use cases also, where memory tends to be provisioned in such a way that it's consumed. The other measure is active memory. So, active memory is really how much of that memory is really used by the workloads. So, you have something called locality of reference, right? You must have heard about those terms. So that indicates, you know, how actively your workloads are using memory, right? So, there is not a single case where you will see that memory is being completely actively used, right? So, typically with our customers, we see only about 20-30% of the entire host memory being used actively at any point in time, right? So, now the BOM is shown to illustrate TCO. So, let me move ahead.

So there are other problems, right? So today, more and more software in the infrastructure is being deployed on a per-core basis. So take any operating system for that matter, or any software license, right? They are all allocated on a per-core basis. So SQL, for example, Microsoft SQL, is $2,000 per core, right? I mean, with discounts, they may provide some discounts, but it's still pretty expensive. VMware's own software is about $350, right? So again, there may be some discounting, but the point I want to illustrate is that software costs sometimes actually are more than hardware costs when you actually look at TCO, right? Now, the key thing here is to understand that when you look at software and hardware costs, right, and memory technologies and how they relate to TCO, you should pay attention to the software costs also, not just the hardware savings. Of course, there is, you know, one of the solutions I present has like a straight off the bat TCO savings in terms of hardware, right? It costs like maybe... 20% of the overall costs of DRAM, right? One of the solutions. But we are not just talking about that. We are also talking about the software licensing costs that we can save, right?

So, this is what I was illustrating with CPU savings, right? The other challenge we have is with respect to how DRAM densities tend to be expensive. As... And as they become denser, DRAM substitution or DRAM replacement becomes very expensive, and it's untenable, right? And the other thing is, we... Customers are not just able to replace DRAMs because once they have their asset allocated and registered, they don't want to change the amount of DRAM on their system very easily. So really, these solutions apply mostly to... Green Field kind of deployments and... I mean, these are some of the considerations that our customers do take into account, right?

So now, our memory tiering solution, right? I mean, we have considerable experience—over, you know, two decades of experience—working with workloads, right? Looking and analyzing pages, and how they are used and how they are being consumed or actively used, right? And now, that gives us... an advantage, which is, with VMware, we have the expertise to actually classify pages, right? A lot of my previous speakers talked about cold and hot pages. But we can actually finally look into the pages and how they are used as well, right?

Now, when you add a cheaper tier of memory, right? What ends up happening is we can move all the cold pages... Or, you know, semi-cold pages to the colder... To the cheaper tier. Thus, creating more space on the host DRAM. So what that ends up doing is actually improve your resource efficiency, right? Now, you have the spare CPU capacity that I probably should have mentioned. A lot of our customers do have spare CPU capacity, right? I mean, more than memory. So they don't... Fully utilize their CPU. And they can't because, you know, their memory is fully consumed, right? Now, with this, what happens is we are able to better utilize their host CPU and run more workloads. I'll share some results, actually, some real benchmark results, which actually illustrate this very point where we actually end up densifying and actually provide better performance, improve CPU utilization, resource efficiency. So we have two solutions today, right? That we are working on. NVMe memory tiering was actually tech-previewed in the previous vSphere release. It's going to be GA'd in the next one. And then we also have something called Project Peaberry. So, Project Peaberry is our CXL-based solution. And essentially, what that does is it provides a CXL accelerator-based solution. And provides a very low TCO and a means to deploy in a greenfield environment and provide instantaneous large capacity. The other key thing about VMware is it's a hypervisor, right? Which means that applications don't need to change. VMs do not need to change. So they run as is, right? Everything, all the complexity, underlying complexity is handled by the ESX kernel, right? So all the customers need to do is they plug in the hardware and then the VMs run as is. No modifications, right? So that's a very key value proposition for our customers. Because they can keep changing this underlying hardware, but none of their software applications need to change.

So now let's go back to our BOM and TCO, right? So on the left, you can see how we actually end up reducing some of the license costs, right? Essentially, we are paying back customers. If you think about saving CPU cores and software being dependent on the core-based licensing, you can see how we are actually paying them back, right? So we took some typical, you know, conservative estimates, and we saw that with Peaberry, we can provide 35% of ROI, and with NVMe-based tiering, we can do 15%. And this results in significant cost returns to our customers, right? So, this is basically $6 million and $2.8 million represents what we give back to customers with these savings, right? And that doesn't even, doesn't even take into account, you know, how we are providing hardware savings.

So this is our CXL-based accelerator, right? So it's a hardware co-design. It has the advantage of no page faults and coherent host memory tracking. By the way, this is CXL type two. I think most of the speakers today were focused on type three, right? But this is CXL type two. So it's, it's a little different in the sense that it needs hardware support and it needs firmware to be written inside the device so that it can do more intelligent things. So we have a team at VMware, which actually develops code that runs inside the hardware today. So we have some specialized hardware accelerator code writers, and essentially they, it, we have this co-design that actually ensures that we can perform a faster tiering than traditional, you know, CXL.mem based tiering. There is low application jitter. That's another advantage of using a type two CXL. We are capable of doing performance-sensitive workloads. The lifecycle is auto-managed, no add-on license. And an important point, it provides four terabytes of extra capacity, okay? And again, you know, I want to emphasize this: four terabytes is not DDR. The card that I'm showing here doesn't have DDR inside. Okay. It's, it's, it's different. Now, can, can someone guess why we have network ports also on the card? We have network ports. So the network ports are used to actually do future enhancements to the solution. We actually can do pooling. We can do remote memory tiering too. So our roadmap actually leads us to do several other things using the same form factor, same card. And, and then, you know, we, we are also looking into other VMware-specific enhancements like vMotion speed improvements, and possibly AI-related acceleration.

So we have, you know, several vendors that we work with. You might have seen all these vendors in, in the floor. So, we work very closely with these vendors. We are collaborating with them. And, you know, we also have a GA target.

Now let's look at, you know, some numbers, right? So, basically, I don't know how many of you are familiar with a tile, right? A tile is a measure of a bundle of workloads, right? Today, actually, a tile that we use for our standard VMMark benchmark represents 19 VMs, running a variety of different workloads. So, the reason VMware came up with this benchmark many, many years ago was to represent a typical VMware customer, right? And essentially, what this shows is we can actually scale the number of tiles from three to six—almost a doubling of the number of workloads that we can run. And the important key point here is, there is no change to the system apart from adding the Peaberry card, right? And the other important point here is the performance impact: so negligible performance impact, right? Less than 5%. So this is totally acceptable for a large portion of our customer base, right?

Next, let's look at some more workloads, right? The leftmost actually represents a normalized DRAM performance, right? And then the middle one actually is a Redis workload performance. So what this is showing is, compared to the normalized DRAM, obviously it's the highest performing item here. So, we can go up to 95% with our solution. So again, it's a cheaper memory solution. It's CXL, but we are able to still drive a lot of performance even with this solution, right? That's the point here. And for SQL, we can go even with a one-inch one. Suppose you have a one terabyte VM, and then you want to make it a two terabyte VM, right? And running SQL. So, we in fact have that experiment where we create a two terabyte VM without any significant decrease in performance, right? But by actually just adding a small cost to your host. So again, this is, you know, it shows that it comes close to a DRAM system.

So, let's jump on to this Oracle on NVMe tiering. Again, you know, this is different from Project Peaberry. This NVMe tiering is our first solution. Project Peaberry is going to be our CXL-based solution. NVMe is going to be the PCIe-based solution. But, this is a completely software-based solution. The point here is to just illustrate quickly, you know, what we see on the Oracle side also. So, basically, it shows that there are two VMs which are doing software memory tiering, and the third VM, which is a DRAM-based VM, right? So, the point of this is by adding this memory, you can add this extra VM and actually get a much higher aggregated performance with both VMs. So, that's the point. So, NVMe, as you know, is far, far cheaper than DRAM, right? So, but look at, you know, how least impactful it is from a performance point, right? But from an aggregated performance point, you get a far more aggregated performance with Oracle. And we have similar results that I shared in the previous slide for Peaberry also with Oracle.

So, here's the summary: NVMe tiering. We have a 100% increase in VM density, right? With Login VSI, it's a popular VDI benchmark. VDI, as you all probably know, is a virtual desktop environment. It's a way to provision desktops for remote users, right? So, a lot of our VMware customers are VDI users too. VMmark, as I mentioned, is an average VMware user. So, with NVMe, we can see a 33% increase in the workloads. With Project Peaberry, which is our CXL accelerator solution, right, we can get, you know, much better resource efficiencies with minimum performance impact and also, you know, much better CPU utilization, right? And both with VMmark and Login VSI, at a 1:1 ratio, right, on the host, we see a 2x density with minimal performance impact. About 5% impact. So, that's basically it.

Call to action: Feel free to contact me, please, for any details on what VMWare is working on with our solution. And, I can definitely talk to any of you and also talk about what our customer experience has been and their pain points. Thank you.
