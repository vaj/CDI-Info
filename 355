
Hello everyone, my name is Viacheslav Dubeyko, so CXL Benchmarking.

So, Adam raised this topic recently, and I realized that this topic is pretty complex.

It's a multi-dimensional problem. Okay, so Adam raised this topic recently, and I realized that this topic is a complex problem because, for example, it's multi-dimensional. For example, we try to ask multiple questions about CXL. For example, what is a killer application for CXL? Or, for example, how can I make my application CXL agnostic? Or, for example, what can I do if I would like not to change my application, but, for example, achieve something like better performance using CXL, or maybe not degrade my performance using CXL? And also, for example, how do I build my CXL infrastructure? Or, for example, how to test my application for CXL if I haven't CXL memory, or if I haven't enough CXL memory? So it's a lot of questions. And, for example, in the future, potentially, for example, we can try to maybe do continuous benchmarking in the background, try to detect maybe some bottlenecks or performance degradation of existing infrastructure. And, for example, if you would like to decrease TCO cost, for example, by using more CXL memories and local DRAM, so how to do this? It's a lot of questions.

And, for example, if you're considering some target use cases, potentially, it could be huge relational databases, social networks, in-memory databases, artificial intelligence, machine learning workloads. It could be a lot of different workloads. It could be now, it could be in the future. And, for example, currently, we're trying to, for example, do sharding, place something like a lot of memory in every node. But in the future, we could have something like a lot of CXL memory, maybe some computational power. It could be a disaggregated architecture. So, and it could be a slightly different environment. And the problem, how to do benchmarking? It's a slightly complicated problem.

So, if we're considering any application from an abstract point of view, so any application, it's something like a set of threads. And if you're talking about memory, so any thread can locate memory at some time point, can delocate memory, or free memory at some time point. If memory was allocated, then an application trying to access this memory, read, write, do something with data and with memory. So, from the memory point of view, any application has something like a memory access pattern. And, for example, it's possible to see that it could be multiple threads; it could be some number of memory locations.

And it's possible to summarize that, for example, we could have some number of parameters that we can use for, like, first of all, to identify memory access patterns. And then try to optimize this memory access pattern by maybe something like modification of these parameters. Because, for example, as I mentioned, it could be some number of threads. First of all, memory should be allocated. Allocation could happen by using some granularity. Usually, then, for example, we have the allocation at some time point. And between allocation and deallocation, we can access memory. And memory can be accessed with different granularities. So, finally, it's something like some multidimensional space that we can, first of all, detect. We can record with memory access patterns. And then we try to play with different parameters to achieve something like maybe better performance—maybe it could be important not to degrade performance at all. And also, potentially, it's possible to play with something like memory allocation policy because it's possible to allocate from different types of memory. And memory is something like a migration policy.

So, if we can, for example, detect memory access patterns, then we need to try to optimize them. It's possible to see something like maybe two fundamental optimization problems. First of all, of course, if you would like to use CXL memory, we would like maybe to improve performance or, as a minimum, not to degrade performance. That means that if we can detect memory allocation patterns, potentially, we can see some maybe repeatable sub-patterns in this memory with access patterns. And then we can find or maybe patterns with more priority. For example, really slow patterns, and we can try to optimize them with memory patterns. And the goal of optimization, namely to decrease the amount of time that we spend on the execution of our algorithm, is one of the potential optimization problems.

Another one, maybe because, for example, if we have CXL memory, it could be a different type of CXL memory. It could be local CXL memory. It could be CXL memory on the switch, maybe on the two switches or something. And finally, every type of CXL memory could have something like its own latency. And it means that we could have something like several types of memory with different latencies. And the problem here, for example, is how many of each type of memory we would like to use. Or how we can build our CXL infrastructure with the goal, for example, maybe memory to achieve better performance. By means of sharing memory, maybe achieve better performance by means of some optimization. So, it looks like that optimization problem could be that we have some memory access pattern. We have some number of latencies. And, for example, how to build infrastructure—CXL infrastructure. What types of memory we would like to use. For example, how many we would like to have local CXL memory. For example, how many we would like to have for maybe some remote CXL memory. And what allocation policy we can use. Something like this—a second type of optimization problem.

And the optimization workflow looks like this: first of all, we need to understand the memory access pattern. Then we can try to find maybe some repeatable patterns, slow patterns. And then we try to optimize these patterns by means of some variation of these mentioned parameters. Or maybe take into account some potential policies or something. And then we can try to emulate this pattern by means of variation of these parameters. And then try to, something like this, change something in these patterns and try to see could we improve performance or could we not degrade performance? Can we achieve something like our goal to achieve something like the best outcome? And then, finally, if we can find something, the next question will be how feasible could this optimization be? Can we change our application or maybe we cannot change the application but we can change maybe the allocation policy? How to achieve this best outcome? And finally, if we can change the application, maybe change the allocation or migration policies, and we can try to play with this optimization and we can try to maybe achieve better performance or maybe not degrade performance. So the goal may not necessarily be to improve performance but, for example, decrease TCO cost because if you could use maybe more CXL memory, it can be cheaper. Then, finally, it can decrease the cost of the whole infrastructure.

But, for example, the difficult question, for example, how to emulate CXL memory? Because if you haven't CXL memory, or, for example, you would like to play with some type of memory, so how to do this? So there are multiple approaches, but not every approach looks good because some hardware prototypes could be not easy to build, or it could be not flexible. RAM disk, for example, a remote RAM disk, could be not so good because it could introduce significant latency, and it could be not so predictable. And if we're talking about co-imulation, so finally, maybe it's good for functional testing, but for latency management, it could be not so good for benchmarking, it could be not so useful, I think. So maybe, my guess is that maybe some mathematical model can help, and this model can be added by maybe thinking about a list data structure because, for example, if you would like to manage latency, for example, by adding some number of items in the list, it's possible to increase latency and manage latency in some more predictable manner, from my point of view. If you're considering something like different types of persistent memory, so it's not so, maybe not so flexible. It's possible, for example, doing swapping, but in this case, the question is how to normalize the result of this testing, so more benchmarking. So potentially, maybe a mathematical model plus a list data structure could help.

And finally, if you, for example, know our memory access pattern and we would like to do some optimization, what is the way, potential way to do this optimization? So, first of all, it's possible to consider changing the allocation policy by means of selecting different types of memory. And also, a second direction could be to use some migration policy between different types of memory. So, it's possible to consider multiple directions. For example, if you're considering size, maybe smaller sizes in local DRAM, bigger sizes in CXL memory, for example.  Priority, but who will define this priority? Maybe the application can do it, maybe some other subsystem, for example. Higher priority in local DRAM, lower priority in CXL memory. Also, for example, if you have a lot of CXL memory, we can prefetch some data in the CXL memory, try to use this memory. Pre-allocation policy, for example, if we could allocate memory by big chunks, so finally, it maybe could help in some way. And also, for example, a lifetime-based allocation policy, if, for example, some memory or some data can live longer, then it could be placed in CXL, if it's shorter, in local DRAM.

And finally, for example, again, it's possible to play with lifetime, and if you can define that this data will be long-lived, then it should be placed in CXL. If it's shorter time, it could be placed in DRAM. And maybe it's possible to use something like a full-system-based policy of management.

So, finally, it's possible to consider something like such CXL benchmarking here more. So, first of all, it makes sense to detect memory access patterns, or have some subsystems that can do this. Then, it's possible to have a memory access pattern emulation tool, because if you know some number of parameters that we can wear, then we can do this emulation. Then, we can use a CXL memory emulator and try to benchmark our memory pattern on this. And maybe, finally, because it could be multiple iterations, so maybe we can use some machine learning subsystems that can do this for us. And finally, we can try to solve multiple problems. Maybe we can try to optimize memory access patterns. Maybe we'll try to build our CXL infrastructure.

So this is something like a potential framework, and also for the future, maybe the Fabric Manager can be considered like a benchmarking subsystem in the background. Because first of all, if you are talking about CXL, mostly it will be a disaggregated architecture. It could be something like multiple hosts accessing this memory. So finally, the Fabric Manager looks like the main point of doing this benchmarking and doing such management. Because also, it's important not only to try to optimize applications, but finally, to detect how the CXL infrastructure works. Do we have some bottlenecks or some degradation? Should we do something about this? And so on.

And I think that open questions, for example, okay, we can do some emulation. And the main question, for example, how to do normalization of these results? And how good is good, numbers? How bad is bad numbers? And finally, how to achieve something like real-life optimization results? So I think that CXL benchmarking is a complex problem. And I think this is my open questions for discussion.

Yeah, so I know a team in Meta that's been grappling with similar problems for a few years. And they released something called DCPerf recently, which is a benchmark suite. What's more interesting though, is how they generated the benchmarks. They used a number of tools and techniques to do that, and I think they expressed interest in, you know, open sourcing first, describing how they've done it and open sourcing part of that tooling stack. And I agree that would be a really cool thing to add to a fabric manager or a fabric controller kind of entity that could talk to host agents and enable all this machinery, extract interesting metrics and traces and so on from applications. But they have some very interesting techniques that they used for that to make it reliable. So they use it to predict performance on future iterations of hardware.

Yeah, sounds good.

In the end, it's again an optimization problem. And funnily enough, this is precisely what AI is about, isn't it? But the more interesting question is, do we know what we want to optimize for? Do we know the knobs we need to tweak? And if we know, do we have hooks for tweaking it? I discussed it briefly with Jonathan. Currently, all the measurements we do within the kernel are centered around latency. Bandwidth would be a good value to measure or to tweak, but we have no way currently, how we could even measure or change bandwidth. It just happens to be. How would you do that?

For bandwidth control, we do have the advantage that some of the stuff done by resctrl allows you to tweak the bandwidth on normal DRAM controllers, so that you can do... We've done a bunch of work on this when looking at some of the migration stuff, and you can tweak them up and down, and you can plot beautiful graphs because you can cap it.

But the problem is, you can't really tweak it. You can set it, and then the only chance you have, either you do the operation or you don't. You can't tell the operator, you can't tell the right, 'Oh, please go slower.'

Oh, no, no, it does. No, it absolutely does that. It will just throttle on the cues on the memory controller, and it will push all the way back to the CPUs. So, yeah. It's not always available on all hardware, but quite a few platforms do support it, and it gives a line. That's the one thing we can do is bandwidth. Latency, you're kind of typically capped at whatever the system does.

For that, people use techniques like the two NUMA nodes, right? And then they twiggle the BIOS settings to... Yeah.

I have a question, more general about the memory, back-end memory for the CXL here. All the examples I saw, it seems that the CXL memory is slower than the DRAM there. But, yeah, is there, like, a different way? Like, actually, high bandwidth memory as the back-end with CXL and...

Hans commented on this earlier, and in fact, he stayed his hand up, but I'll let him talk about it then. I thought he wasn't paying attention.

Oh, I do. Well, at the end of the day, it's all down to hardware. And surprise, surprise, you only get a benefit for CXL if you're using as much hardware as is available. You will not go into the trouble of inventing your own kind of hardware or DRAM for CXL. No, you will be using normal, available DRAM. That's kind of the point. Why would I need to do something else? Which then also means that, well, we already have a DRAM connector, and that's the normal DRAM slots. So, you'd be hard-pressed being faster than your normal DRAM slots because you're essentially... I mean, the idea is that this would be the optimal way of talking to it, the optimal way of talking to it. So, I don't really expect them to be significantly faster than your normal DRAM. That would sort of imply to me that the manufacturer really, really, really messed up.

I happen to work on the NVIDIA stuff, of course. The GH200 there, they actually kind of up that way. Like, they are using the high bandwidth memory. It could be like 3.5 terabytes. And every link is C2C. It goes to the system memory. Yeah. Okay, yeah. So, that way, actually, the device memory is way faster than the system memory there. And...

For these devices, yes.

Yeah. Yeah. But why CXL don't do... Like, it's still...

No, it does. You will. If you use that with CXL, you will find it's faster.

But from that side of things, if you're doing conventional CXL PHYs, et cetera, you won't. You will find it's perhaps faster than inter-socket stuff, but you're not going to get there. Yeah, it's fundamentally a PCI PHY. However, there are certain standards that run CXL protocol over entirely different physical stuff. And at that point, yeah, sure, you might be in a situation where you might put HBM down. But at this time, most of the stuff is focused on stuff on the PCI PHYs. I think. If anyone has any other devices, now's the time to shout. You may get extremely high bandwidth because we do have the option to interleave an awful lot of CXL devices. But the latency is always going to be capped. Yeah. Well, it's usually the host end that's the problem. It's just how many things can you wire up because it's pin limited.

I think this is the problem. How to be faster to use slower memory.

Any more questions? Okay. So, on that note, I think we'll thank the last speaker. Thank you.
