
Okay, so it's really great to be here and to talk about DRAM fault tolerance.

So, I think we all know the importance of the DRAM fault tolerance, and also, due to the very excellent error correction capability for both random errors and burst errors, we all know that the Reed-Solomon code has been widely adopted in practice. And also, I think, if you remember from your college days, like every single coding theory textbook tells us that the error correction code decoding can only correct up to half of the minimum distance. It's really kind of bounded, strictly bounded by the code's minimum distance. So that is what we all know. And that is what the whole industry has been doing for all the decades.

And actually, that is not necessarily true—that the error correction code decoding or DRAM fault tolerance has to be limited by the minimum distance of the code.

So, actually, when coding theory just emerged as a kind of new research area about already almost seven decades ago, Peter Elias at MIT actually asked the question: Why can't we go beyond the minimum distance of the ECC? His motivation is very simple. That is, the minimum distance bound ECC decoding actually only searches in a very small Euclidean distance space, missing a lot of opportunities to do error correction. And even one way can go beyond the minimum distance. So.

So, like, actually, for example, we all know that, now for DDR5 DIMM, we use an 80 64-byte—this 80 64-byte Reed-Solomon code—to protect a 64-byte cache line. And if we just use the traditional Reed-Solomon code decoding algorithm, actually, it's just a search of, you know, a very tiny space in the code space for the error correction.

And so, motivated by that observation, Professor Peter Ellis, in the 1950s, proposed this principle they called "list decoding." That we can go beyond. We can go beyond the minimum distance of the code by searching in a larger space, that is, to capture those missed opportunities to improve the error correction capability.

So, that is really kind of a very beautiful concept and very well-justified, but unfortunately, it turns out the practical implementation of the list decoding is almost impossible. You know, that once we go beyond the minimum distance, we don't have a well-established decoding algorithm. And then, the computational complexity quickly just, like, becomes out of control. Though we really have no way, in the general purpose sense, to practically implement this list decoding strategy. Even though it has been very well documented and studied in academia, there is a huge potential and opportunity to go beyond the minimum distance for error correction decoding. So, then actually, at Scaleflux, what we have done is that we realized, actually we figured out a way to practically implement this list decoding principle. And we apply that for our first-generation CXL memory controller.

And, yeah, before we present that, let's very quickly go through a review of what is going on in the Reed-Solomon code decoding. So, the standard way to do the decoding is that we have just the four steps.

And their computational complexity is listed in this table. And clearly, like for memory fault tolerance, we want to take this fully parallel implementation to minimize the latency and to maximize the throughput.

But unfortunately, once we go to the fully parallel implementation, the computational complexity for the second step and the third step very quickly increase. That makes even the standard Reed-Solomon code decoding non-trivial for efficient silicon implementation.

And it's actually like, in current practice, that the industry tackled is even for the standard decoding algorithm implementation. What the industry has typically done is that we use the cold-water interleaving instead of protecting one 64-byte cache line on its own. We partition the 64-byte cache line into four 16-byte smaller segments. And then we use the smaller Reed-Solomon code to protect every 16-byte segment. Then we can reduce the implementation complexity. But of course, we sacrifice the error correction capability. So, that is what is typically done in practice.

So now, we are ready to introduce our solution. Actually, our solution is very simple. It is based upon two very simple observations. One is that whenever we read a 64-byte data from the DIMM, almost always, no more than two DRAM devices will contribute errors in that 64-byte cache line read. So, that is observation number one.

And the observation number two, as we discussed earlier, like the computational complexity problem, mainly comes from the second step and the third step. Interestingly, that second step and the third step, their purpose is to identify the location of the error. And then, the last step is just to correct the error. So intuitively, if we already know the location of the error, then the second step and third step, they will disappear. Then we can much more efficiently implement the decoding. So, that is just two very simple observations.

Then, based upon that, we are ready to introduce our DRAM-oriented Reed-Solomon list decoding. So, the key idea here is that we convert the traditional error correction problem into a set of eraser corrections. Here, the eraser means we already know the location of the error, but we don't know the value of the error. We simply just need to figure out what the value of the error is. We don't need to figure out the location.

So then, taking advantage of the observation that is, if we create a 64-byte cache line from the DIMM, only up to two devices will contribute error. Then our idea is that, okay, so we exhaustively examine all the possible two devices that can contribute error. So then, 10 choose two; we have 45 possible combinations of those two devices that can contribute error. Then we examine all of them. So, this here shows like, when we receive like 80-byte data read from a DIMM, and then we feed that data into 45 parallel eraser decoding, and then we generate 45 Reed-Solomon codewords, and then, based on the simple search, we just can nail down which one is the correct codeword that we should use. And that is pretty much all the basic idea of our design solution. And that happened to be the first practical implementation of the list decoding concept that has been invented 70 years ago. And so, actually, you might wonder, like, even though the eraser only decoding, even though that can be much simpler than the normal error decoding, but we have 45 of them. So the complexity might still be a problem. And fortunately, like, we have very good engineers then they can figure out a way to do a very elegant arithmetic optimization that we can further push down the implementation complexity. Then we can very efficiently implement those parallel 45 parallel eraser decoding. So that is the basic idea of this. This is our, we call the DRAM-oriented Reed-Solomon list decoding. So we leverage the observation that only up to two devices can contribute error. We dramatically reduce the search space. We need to search for the correct codeword.

And then, we're actually—we are very excited about this kind of discovery. Our first application is for the CXL memory. And we know that for CXL memory, like every 64-byte cache line, we need to add one to up to three bits of metadata. So, to our understanding, current practice is that, okay, so then because we need to store a couple of bits of metadata, then I take—I steal one byte from the coding redundancy. And then, here we only use 15 bytes of coding redundancy to protect this 64-byte cache line. And that is what is being done. And to our understanding, so clearly, this—we waste some space. And more importantly, we use one byte less of coding redundancy. So, the error DRAM fault tolerance strength is sacrificed.

So, our solution is that we use what we call the zero-cost metadata embedding. And we leverage the very strong error correction capability of our list decoding. And then, we still use 64-byte plus 16-byte of a Reed-Solomon coding redundancy. We don't sacrifice on the error correction capability. And then, when we store the data, we simply puncture away the metadata because we can, on the fly, reconstruct the punctured metadata without sacrificing the error correction capability. And then, over there, we further enhance our solution. We call the metadata-aware list decoding. And certainly, to support this feature, the implementation complexity will increase. So then, we figured out another further solution to really combine, leveraging our deep understanding of the coding theory and our deep experience on the VLSI algorithm implementation. Then, we have a very efficient parallel decoder in support of this metadata-aware parallel list decoder.

So then, we can talk very quickly to talk about our evaluation and the implementation. So, we know that actually, for any kind of ECC decoding—not only the Reed-Solomon—so, for any ECC decoding, the output could be one of those three possible outputs: like a successful decoding, like we successfully reconstruct the data. The second one is detected failure; that means, like a decoding fails, but we know, the decoder knows the fails. The last one is the most problematic, like the decoder generates a valid, but incorrect, the codeword. The decoder doesn't know; the decoder thought it already correctly corrected, but it is not a valid, it is a valid codeword, but is incorrect codeword. So, that is much worse than the second scenario.

And so, then, for this—actually here—this table summarizes the comparison between our solution and the standard Reed-Solomon decoding algorithm. So, here, we use an 80/64 Reed-Solomon code. The minimum distance is 17. The conventional decoding can correct up to eight symbol errors. So, we can see, on the left-hand side, when the number of errors is less than eight, then everybody is happy; we can correct all the errors. But once the error number goes beyond eight, that means we have one DRAM chip failure, and then we have a second chip contributing errors. In that case, conventional design totally fails. They cannot correct any error. But for our solution, we can make sure that even up to 12 errors, we can guarantee almost 100% of the error correction. But we still need to kind of play some trade-off between the second detected failure and the third missed correction.

And so, then, we have already implemented this list decoder in our first generation CXL memory controller, and we already tipped it out. And also, like, the decoding latency is sub-five nanoseconds, and the one engine can achieve almost 40 gigabytes per second. And actually, in our final chip, the decoder only occupies a small percentage of the chip, like that area. But we can go far beyond the traditional—like this traditional standard of Reed-Solomon decoding. So yeah, we're very excited about this. After 70 years, when Professor Peter Elias at MIT proposed this very beautiful concept of list decoding, we are the first ones in the industry to bring this beautiful concept into practice, to make it work in silicon, and then to make it work for our DRAM fault tolerance.

Okay, so yeah, in summary, like, yeah, we are very fortunate that we caught this wave on this CXL memory and memory controller. And then, over the course of developing our CXL memory controller, we figured out a way to develop, to implement, this list decoder that achieves the best-in-class DRAM fault tolerance, way better than anyone else on the, like, really on the market. And that is really leveraging our understanding of the DRAM characteristics, the coding theory, and the VLSI signal processing implementation. So, we really hope, like, we can work together with the industry to continue to push and raise the standard of the DRAM fault tolerance.

So yeah, this last one is a call for action. Certainly, like once—I think one question is, once we're able to achieve much stronger DRAM fault tolerance, how can the whole system take the best advantage, or take full advantage, of this strong, very strong error correction capability to improve performance? And, how can we take advantage from different angles? Yeah, so that ends my talk. Thank you very much.

Thank you, Tong.
