YouTube:https://www.youtube.com/watch?v=D66W7eqFbhc
Text:
This morning I mentioned Project Gismo and now I'm going to tell you all about it. This has been a very exciting project that's been going on over the last year.

Because people have been thinking and wanting about shared memory, but it's not clear how soon we're going to have it. The reason that shared memory is interesting is because modern computing is about how computers are going to work with each other. And there are, I think, different philosophical debates on the trade-offs between share nothing systems to share storage systems to share memory systems. And shared memory systems have been pretty much an impossibility because before, when you needed to build it, you needed to create very customized, essentially, multi-processors and how they can work with each other in a NUMA way. And to have a more loosely coupled node to operate with shared memory was not possible. And therefore, the predominant way of dealing with this is through I/O. And I/O including networking I/O and storage I/O. And many of us made our career out of these I/O systems. Myself, my co-founder Shuki here, we have been working in storage for the last 20 years. And it gave us a lot of pleasure and gave us a lot of pain. And we had a nice career making good things out of storage I/O. And similarly, many good and smart people made a career out of networking I/Os and made those I/Os faster. But however fast we make it, it is not that fast. Because whenever you need to hit stuff on the wire, go from node A to node B, or whenever you need to persist things onto storage, onto a different media, you often need to serialize and deserialize your data, turn them into a format that's best fit to the medium that you need to transport or you need to store it on. And often you need to make copies, and sometimes more than one copy. You need to copy from the nodes to the network, copy from the memory to the storage. And often you need to make a copy on the source and you make another copy on a destination. And that's if you're doing things efficiently. If not, as you travel through the stacks, there could be multiple copies being created. But for sure, there's at least one copy that needs to be done from one node to the other, and these copies waste time and they waste space. It not only makes things slower, but it also magnifies the amount of memory you actually need. And lastly, if you go to storage, there are different speeds to different media. Before you were dealing with hard drives, and now with NAND SSDs, and these are slower, especially in latency. Bandwidth, I think, is kind of the difference in narrowing. I think as one of the talks, Srijit was mentioning in the morning, by latency, there's still at least a couple of orders of magnitude of difference between a storage latency and a memory latency. And there are at least a one order of magnitude difference between a network latency and memory latency. And therefore, when you need to incur I/O, it slows down the application. And these are one of the two walls that we are dealing with in distributed computing. One is memory wall, and that refers to the bandwidth between the processor and the memory. The other is the I/O wall, and that refers to the latency and bandwidth limitations you see when you need to go through the network, or when you need to go through the storage.

Now, one exciting thing about CXL is it provides an alternative, provides an alternative to the I/O. You know, I/O is an interesting word. You need to look at to see how it's defined. Arguably, you can call memory also a kind of I/O, but what's different with memory is that now you don't need to serialize and deserialize, which is associated with a classical I/O. You can just do random direct access to the memory. And in this case, you can do that random direct access to the shared memory as you were doing to local memory. And secondly, you do not need to copy it. When you are shipping a particular piece of data from node A to node B, you do not need to make another copy from the memory of node A to the memory of node B. You actually just have one copy that's on the shared memory. And lastly, you don't need to incur that difference in media speed. You do not need to go to an end. You're always on the, you know, whether it's DRAM or whether it's another type of memory media, and that's the memory speed you are working with. So it's, and CXL for the first time, provide a possibility for you to transport a piece of data from node A or node B, or to allow two nodes, node A and node B, to share the same data without incurring network I/O or storage I/O. And this was specified in the standards to be available in the 3.0 time frame. Because one of the requirements to achieve shared memory is you need to have cache coherency between the CPU caches on node A and node B. And this is sort of the cost you pay in order to avoid those serialization, deserialization, avoid the copies where you need to have this direct CPU to memory access. You need to achieve that cache coherence. And it is very expensive to implement if you are to support random access to, you know, read/write from any of the node to any region in the memory. And therefore, it is a task to be completed in hardware and in the 3.0 time frame. And 3.0, I think people are estimating probably going to be available 2025, 2026, 2027, depending on how optimistic you are. And there are also questions whether this is going to be fully implemented in hardware to support the cache coherency in 3.0. So the timeline of 3.0 is still uncertain. And so we have been thinking, is there a way for us to allow people to start using cache coherent shared memory even at 2.0 time frame? And the answer is yes. And the trick is, you know, we want to take baby steps. We want to allow a first mechanism to allow people to use shared memory where multiple nodes can have direct memory access to share memory, but to restrict it in certain ways that it's useful. And at the same time, it's not too expensive in terms of performance. It doesn't cost you too much performance when you need to perform those cache coherence tasks.

And that's Project Gismo. And the API we settled on is an object store access API where multiple nodes can access memory in the form of an object store that you can create. Any of the nodes in the cluster could create a memory object, and any of the nodes in the cluster could read that object simultaneously. And at any time, the creator of the object could decide to destroy or delete the object as well. So it's a very simple and very common API. And even with something as simple as a common that, we actually found some very interesting and very useful use cases, which I'm going to dive into in the next 20 minutes. And this shows sort of an architecture of a basic Gismo implementation. You have three nodes here. You have various kinds of applications that can run on Gismo. We provide an SDK that these applications can integrate with, and a very simple API they can call. And there is a Gismo manager that sort of manages the metadata and coordinates among these nodes in terms of access to their shared memory. And there's still some local memory on each of the nodes the application can use. And for the data they like to share between these nodes, they go directly to the CXL memory, and it will be direct memory access to that memory where the object are stored.

So now let me go into the use cases. The first use case is in AI/ML. And the software that we integrate with is a software called Ray. Ray is a orchestrator scheduler for AI workload. It is created by the same group at Berkeley that created Spark. And people were using Spark for AI, but they figured Spark was not adequate. So Ray was Spark.next for AI. And it has gained more popularity in the recent months because it has very good support for reinforcement learning, and because it's used by open AI for the ChatGPT and GPT-4 workload, it's actually using the Ray platform to orchestrate the work. And on the left-hand side is how Ray looks like today. And essentially you can have many nodes. Each of the nodes can have many workers, and they have a relay that these workers can talk to. Within the relay, there is an in-memory object store it uses. And the current object store it uses is called Plasma. It is a local in-memory object store. So it can allow different processes on the same node to access the object that's in the local shared memory. And what Ray also implemented is a global lookup system where you can look up the object on any of the nodes. But if the object is on actually a node that's not itself, what it does is it incurs it uses a network. It would create a copy of that object on the local memory, and then using Plasma to access it. So when it's local, it's great. It's perfect. In fact, Ray has this philosophy of passing by references and using shared memory to do things. But when it is moving across nodes, because there was not CXL available, it needs to use a network to create extra copy for it. And that takes time, and that creates redundancy in the usage of memory. And how Gismo changes it is that it uses CXL shared memory. Therefore, we replace the local in-memory object store with this shared memory object store. That's Gismo, so that the lookup continues to be global. And now the access also is global, direct access. You do not need to use a network, and you do not need to make a copy for it. Any of the nodes can just directly look up there. And now let me show you a demo how this works.

In the demo, on the original, you have 16 gigabytes of local memory used for Plasma on each of the nodes. And in the Gismo demo, you have 64 gigabytes of CXL shared memory to hold that data. So this is actually running. First, we're going to show how it's running on the original Ray. And if you list out the nodes, you'll see there are four nodes. Each of them have four cores. And so there are a total of 16 CPUs. And we are creating an object store of 20 gigabytes. It's 100 partitions, 0.2 gigabytes each. And then we run a kind of a benchmark for Ray that's a shuffle benchmark. It basically-- shuffle is a very common operation. It needs to move the data around. And how it's running the shuffle across these four nodes. And as you see it run there, there is some text there showing it's actually spilled because it ran out of memory a little bit and it's moving all those data around. And it took about 57 seconds to complete. Now, if we're using the Gismo system where we use the shared memory and, again, create four nodes, create 20 gigabytes, we run the same shuffle benchmark and there is no spilling. And it takes 30 seconds to complete. So it took about roughly half the time.

And here are some of the data that we got. I think when we demo with a shuffle of 20 gigabytes, you can do the same demo with 50 gigabytes. And with 50 gigabytes, it's the difference even a little bit more, about 280% improvement in terms of speed. When you're looking at actually the actual grabbing of the data, if it's on the local, if the object is local, we cannot go faster than before because it was on the local memory. CXL memory was a little slower. But even though CXL memory is a little slower, it didn't show up in this case. The baseline is 0.4 seconds. This is also 0.4 seconds. I think just the difference is small enough to be measurable here. When it is to getting a one gigabyte object from another node on the baseline, because they need to incur the network and incur the copy, it took 2.7 seconds to get one gigabyte. And with Gismo, it took 0.4 seconds. So it's about seven times faster when you need to grab it remotely. So this shows that there is significant improvement when you need to access data remotely. You do it over shared memory compared to go over a regular 10 gigabit network.

All right. So now let's see the reason for this speed up. Really three reasons. One is that there is no actual networking I/O that took place in this case. Secondly, there is zero copy throughout this whole process. And the third, because of the lack of the actual use of memory, in the first case, you see there's a little bit of spilling that took place, meaning some of the nodes actually exceeded the 16 gig of memory that was allocated. And that slowed things down a bit as well. And where you have shared memory, you basically reduce the number of copies, therefore have more efficient use of memory, so that it's less likely to go into memory spilling situations also. So these are all the reasons for the speed up in this case. And we are continuing to work with the Ray community, with AnyScale, which is a company behind Ray, as well as with other AI platform companies to look at other ways where a shared memory system can help improve the performance of AI systems. And this includes both training as well as inference situations.

And what we have found out is not only AI, that shared memory can be also a performance improvement methodology for databases. The first of such cases is working with a new kind of database called HTAP database, stands for hybrid transactional analytical databases. Hybrid transactional analytical processing databases. And the first company we work with is a startup called Matrix Origin. And they are creating a new scale out database system that can run in the public cloud as well as in private cloud. The architecture, this is probably oversimplification of the architecture where the actual data is being placed in a storage service such as S3. And then there is a transaction engine that does all these queries for these databases that are scaled out. I drew three, but they can be 30 or they can be five or they could be one. So it's kind of a, it's an elastic, scalable, scale out system for the transactional engines. But because the storage is slow, it must have a cache locally to each of the nodes in order for the database to run these queries efficiently. And right now, each of the engine needs to have their own cache. And when you have your own cache, there are a number of issues in terms of performance and complexity. One is the hit ratio. The cache hit ratio is not that high because if node A has it in its cache, did the query before and node B doesn't have it in the cache, when node B needs to access data, it needs to warm up the cache again from storage. So there's no kind of leverage across the node on the local cache. Secondly, when it actually does it, it replicates the user memory. So there are like multiple copies of this cache because they have each of their own cache. And thirdly, when some of the nodes update a field or a role in this HTAP database, then the other cache will need to be invalidated and then need to be updated again. So this cache invalidation across so many caches can be very expensive and complex for the system to manage.

So what we are able to do with them in this early collaboration is to replace those local caches that's associated with each of the transaction engine with a CXL-based shared memory as cache so that each of the nodes, there is very little, there's zero change to their application logic. They continue to access as if it's a local cache, but it's actually being shared across these transactional nodes. And it basically solves all three of the problems I mentioned. Now the cache can be leveraged between the nodes. If node A accessed it, it's in the cache, then node B can also enjoy the cache already without warming up that cache again. So the hit rate will be increased. There is no more extra copies. That's unnecessary. So it only uses one gig. If you have one gigabyte of database that needs to cache, you use one gigabyte instead of 10 gigabytes if you have 10 nodes. And that if you update a field, then only that cache needs to be updated. You don't need to invalidate all the other caches that's out there. So having a shared memory cache is a clear performance improvement and complexity improvement for this HTAP database. So that's the second use case, which is a shared memory cache for a distributed database.

And now we have the third use case, which is also for database. In fact, I see Ting just walked in here and his company called TimePlus. TimePlus is a next generation streaming database that essentially processing the streaming data, such as time series, or if you have real time information that's being generated and you need to process and query that on the fly, that's where you need a streaming database. And when you have a streaming database, it needs to process things very fast. And what we are collaborating with TimePlus team is to explore a better failover design based on a shared memory, CXL shared memory. And so in this case, you have two nodes. One is a primary node, the other is standby node, and there are various data, query data, query index, and state that need to be shared across them. And today they are shared using storage and using networking so that when the primary fails, the secondary node can take over the job.

 And with CXL shared memory, you no longer need to invoke networking or storage to do this. They just share the state and when a node A fails, then node B can take over. So this suddenly become a simpler and faster mechanism to do it.

We are actually working on it today. And I'm glad Ting is here because later on today that he will give you a full presentation of what streaming database is all about and the work that we have been doing in collaborating and some early numbers indicating the improvement that CXL shared memory can bring to the system. And we are at the very beginning of that collaboration. We think this is going to definitely expand to even better performance results as well as other areas where this database can take advantage of CXL shared memory. So those are just three early examples how the Gismo shared memory library can help applications improve performance, improve complexity, and having a superior design compared to before. And we are very open to others. The reason we are making this announcement is to recruit more application developers to work with us, to give us feedback so that we can have this library to be a form where more application can be used. Our alpha version of this library will be available in a couple of weeks, available to anyone who is interested to try it out. And we hope to have a GA version of this library by the end of the year.

And this is the API this library has, which is pretty simple. The Gismo connect and disconnect is for it to connect to the Gismo manager, for it to start to work. The create and seal is the way how you create an object. The get and release and how you read the object. And delete is how you can delete the object. And then we have a subscribe where you can listen to the notifications. So that's all the API it has. It's a very simple API that allows, essentially provide the first, we believe it's the world's first mechanism of shared memory that allow you to use it on top of CXL.

All right. So the conceptualize, as I mentioned in the morning, this really introduced memory as an alternative for you to transport data from A to B. Therefore, memory now becomes your network. It also is a way for the memory to become a way for node A and B to share data. And therefore, memory is your new storage that replaces storage. And this leads to a world where the computing is going to be centered around memory.

And we have an email address Gismo@manverge.com. So if you have any questions, if you're interested to give it a try, if you're an application developer of distributed applications, if you're working on AI ML systems or distributed databases or HPC, and if you're looking at differentiated performance advantages of your application, comparing to alternatives, contact us. We love to learn about your applications. We love to improve the platform we can provide to you that can help you build a better system.

So that's it. That's about Gismo. Any questions?

