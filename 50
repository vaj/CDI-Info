
Okay, so I'm going to talk about CXL and confidential computing.

Sam's plan as a previous presentation is to scare people. And I'm going to go pretty quickly on what confidential computing is, what it means for a device, and then go through finally CXL.

So confidential computing, I'm taking the definition from the confidential computing consortium, which is part of the Linux Foundation. So you want a trusted execution environment. It means that your data, you're running inside an isolated environment. And only whatever you trust is able to access your data. So usually it means that you can run your workload without the IP adversary or anybody else being able to spy on you or to see whatever you're doing.

So it comes with a bunch of requirements, obviously. You need to be able to attest the platform you're running on. If you cannot attest that the CPU you're running on is providing you an enclave, then you don't really exist. You want data integrity, making sure that nobody can modify or alter the data you have inside your environment. You want confidentiality, nobody can spy on what data is, so encryption really. But not only encryption, isolation is also very important. And you want code integrity. So that's often seen as an optional thing, but it's also very important if you don't want somebody just to modify the code to extract the data you're running inside your TEE. So most of the time, TEE is a true hardware enclave. So Intel, AMD, and ARM, they all have their different naming for that, or also have a different thing for that. Everybody has a name for that, but it's just a hardware enclave, really, where your VM, your usually trusted VM, can run.

The threat, really, is any other application on the host. The host operating system is also seen as a threat. The system administrator is seen as a threat. The service provider, cloud provider, is seen as a threat. So it means that you're not trusting anybody, basically, in that kind of scheme. You are a customer, you want to run a VM in the cloud or wherever, but you don't want the cloud provider to be able to access your data or to be able to modify your data or to do anything with your code or application.

A bunch of things that are optional, like code confidentiality when you launch your application and so on, and also work over things. So if there is some kind of event that happens, it's not just somebody attacking you, but it might be some other fault happening, some signal integrity and whatnot. So various things if you want to recover from a state of panic, basically.

I want to touch on one thing, what I call the pyramid of trust. As soon as you have one layer that is compromised by any means, I'm talking generally here, it means that all the layers above it are also compromised. If your IP adversary is compromised, then it means any VM running inside that host is compromised, unless you have secure VM with Enclave.

So the outcome of that is that if you want to protect and create Enclave, the only way to be able to achieve that is by having the hardware as the lowest layer, is by making the trusted execution environment inside the lowest layer. And so the security is as strong only as the lowest layer. So one of the bonuses of making the Enclave inside the hardware is that you can remove the operating system and the cloud provider from the first base. So it means if the Enclave is provided by the hardware, you don't have to trust your operating system, the BIOS and whatnot that is running on your computer.

So roughly the architecture, how it looks when we're looking at VM. You have the CPU with a security module, you have your IP adversary, which is like most likely Linux, I mean with specific Linux numbers after all, and you have your trusted VM. And basically what happens is that whenever you have memory that is assigned to the VM, the VM can first authenticate the memory and say, okay, I'm accepting that memory and talk to the CPU security module. And the CPU security module is going to program a bunch of tables and isolate the memory from the IP adversary. And at that point, the trusted VM can start using that memory. And so that you have like the security module that's enforcing isolation from everything else in the system.

So what it means for device is that if you want a trusted execution of earn money in the device, you want the same kind of thing, really. You want to be able to test the device. You want that the device protect the integrity of the data. You want the device to have confidentiality for the data. You want the device also to have code integrity for the code running on the device. And again, you want that to be in hardware.

You know, same as for CPU, really. But again, same as for CPU, you cannot trust all the blocks inside your device. You know, your device, like I'm presenting here, a very basic abstract device. And your device can have so many blocks that you cannot really trust every other block. So, you know, usually you have the idea that you have this kind of root of trust. And then everything else falls from that block.

Another issue with the device is that you also have to think about how one hardware block can be used to attack another hardware block. And so you have to use, to think about boundaries and what you can do also for debugging and so on. Because often devices, unlike CPU, have not been isolated as much as CPU, really. So it means that when you look at debugging feature on, I don't know, GPU, for instance, or some kind of accelerators, really. Often if you use JTAG or whatnot, you can access the full states of a block. Which means you can also access the data as inside a hardware block. So which means it gives you a window into whatever application is running.

So if you want isolation, you want device enclave. So the way we're doing today with PCI Express is things like SR-IOV and so on. So you can have a virtual function that is assigned to a specific TVM. And only application inside a TVM run inside an enclave on the device. And the device can isolate every virtual machine workload.

So, yeah, the checklist really is trusted execution environment. And the way to measure device isolation for integrity. And obviously you also need to protect the traffic between the CPU and the device. And that's going to be really the chunk of the talk here. Because, you know, CXL is a fabric.

So the issue is you want to protect the communication between the CPU and the device. There's many ways that somebody can attack that traffic. You can have a PCI Express switch or a CXL switch between you and the device. And somebody might have taken control of the firmware of that switch. Or you can have a cable and somebody just puts some kind of interposer between you and the device. And what the attacker can do is, like, you know, modify traffic, inject traffic, delete traffic, replay traffic. Spy on the traffic. Look what is the data. And also do side channel. So the same memory has been written again and again with the same pattern, same memory. That might be a way to guess something. So the integrity is going to protect the first four, actually. And, yeah, well, the encryption is going to protect the last two.

So integrity, the idea is that for every message you have on your fabric, on PCI Express, CXL, you want a message authentication code. So it's basically a hash of your messages, a cryptographic hash of your messages that say, okay, you need to know the key to be able to compute the cryptographic hash of the messages. And it will protect you against, you know, all the first four, like, modifying traffic, being able to replay traffic because you also use a counter, usually. So it means that both sides look at every message and they have a counter and they keep incrementing and they keep in sync. So it means that they expect to have a certain number of messages.

So that's for integrity. For encryption, the idea is that you only protect the data. You're not protecting the address or the code or whatever of the traffic. You only protect the payload of the PCI Express. So, you know, it can be a memory read. So you're going to protect the memory, not the address or things like that. Usually you also want to use some kind of salt or counter again. Because if you use the same encryption, depending on the encryption algorithm, again, if you use an encryption algorithm that for the same data gives you the same output result, then somebody can use that as side channel attack because it's seeing the same pattern being written again and again. And so that's also a way you want to protect yourself against.

Another thing you want to do, because you have context on both sides, you have context on the CPU side, your trusted VM, and your trusted VM is going to have a context on the device side too. And so you would like to be able to assign traffic so you know that one traffic message is assigned to a specific context on the device. Otherwise, a context on the device might pretend to be attached to a different context on the CPU and be able to spy on that other CPU context.

So that's one thing you also would like to have. A touch on topology. So, you know, you can have very complex topology, especially with CXL. So you can have like a CPU connected to a switch and the switch can be connected to a fabric and the fabric is multiple switches, basically. You know, any number of reasonable limit, I think, on CXL, like 4,000 maybe, but it can be a big number. And so you can have like, you know, many, many devices between the CPU and the end device. You can have many, many switches. So that can be an issue.

So you have two kinds of encryption and protection. You can do point to point. That means that you go from CPU to first switch, encryption and integrity between the two. And then this first switch is decrypting the traffic and re-encrypting again for the next destination. And so it's up to a point to point. So, you know, from one point to the next, which means you have to trust every single point in the path. Otherwise, if any point in the path is compromised, then that point in the path can escape the traffic and access the traffic in plain text. So you completely lose your protection if you do point to point and one of the points is a weak point.

And if you do end to end, the idea is that only the two end points need to know about the encryption keys and the integrity keys. And only the two end points can understand each other. It means that any point in the fabrics is just passing along messages. So if you think of it as like TCP and SSL, really, like, you know, you have a packet that is protected by SSL and all the switch on the internet, they're just passing along packets. They don't care about what it is. Or should not care about what it is.

So, yeah, so that's the big thing about computational computing and what it means for CXL. So maybe a quick overview of CXL. It's really a new protocol that is geared toward cache-coherent load and store. You know, it allowed to add memory to CXL that be of like the main memory you have. You can also add accelerators and so on. And one of the things you have to understand from that is that it's dealing with cache line, 64 bytes. So it means that every message on CXL cannot have error or, you know, the metadata for the message cannot be too big. Otherwise, your bandwidth efficiency is going to be really bad. If you have more than 64 bytes to describe the 64 byte of data, then, you know, like, what's the point of your interconnect, really, at that point? So you want to have very few fields. And that's what CXL has, very few fields. So just the physical address and few accelerators. So there isn't much for the header, basically, which is an issue for security.

One of the issues with CXL, it's all about physical addresses. So it's HPA, all physical addresses. So there is no IOMMU. There is no filtering of anything. If you are CXL devices, or type 2 or type 1 devices, you can access any memory on the system. And you have full access. That's what the specification says, really. So there is no IOMMU, nothing that can block you. So it means you must trust the device, that the device will not try to read or write or snoop to things that it should not. And there is no more central access control. You know, you don't have an IOMMU or some central point where you can program the access control. It means that you have to program access control everywhere in the device and every device you might have. So that's one of the issues with CXL when it comes to security and computer computing. You have to keep in mind.

Another issue is traffic identification. So I talked about it, you know, when you have multiple contexts on the CPU and on the device. How do you identify the traffic? Well, you can't. There is no way to assign an ID inside the header. So there is no way to identify traffic on CXL. So when you have a device asking the CPU for a specific cache line, the CPU has to trust that the device is authorized to access that cache line. There is no way for it to know if the context on the device is actually authorized to access that.

Another one is CXL IDE. So CXL IDE is like PCI Express IDE for those who know. It's integrity and data encryption. On CXL, it's only point to point, which means you have to trust every point. In the past, you know, kind of bad for a TCB. So TCB is a trusted computing base. So it means everything you want to trust. And if you want confidential computing, you want to limit the trust of the TCB. You want to limit the number of devices you trust. The more people you have to put inside your circle of trust, the less, you know, the more scary it should be.

And the last one really is rogue devices. So CXL memory device, all the ones that are going to hit the market have an ARM CPU, really. Or a CPU. It doesn't have to be ARM, but so far I've only seen ARM. And it's pretty powerful. So, you know, it's not a simple microcoder. We're talking about like powerful CPU core, actually. And, you know, how do you feel about that? How do you feel about having a CPU in your memory, really? Because that CPU can access all the memory, that is CXL memory. So, yeah, maybe you should be scared about that. So what happens if the attacker takes control of the firmware anyway? You know, like because like they manage to break the device or the supply chain attack or whatnot. Or they found a bug in the firmware and they are able to, you know, live attack the firmware. And they can also use that to escape memory. So you have two TVM on one CXL device. You know, you have like the device sniffing out one TVM context and escaping it to another TVM context.

So we talk about multi-host. That's even more scary if you think about it. Because you can have multiple hosts and one host can be attacking another host. So, you know, like the host thing is like you have multi-fabric, server A, server B, and they're all using device A and device B. And they can use -- server B can try to use device A or device B to attack server A.

That's also scary.

And finally, the multi-head thing. We'll also touch about it. It's kind of the same model. Instead of having a switch, you just have a device that has multiple connections. So it's like a switch and a device integrated together. But you can have multiple different hosts connected to the same devices. And again, that device will have firmware, will have CPU and so on. So you can also attack the device.

Anything else that scares people with CXL? I mean, like that's the main -- all the things that scares me. But there's probably much more that you should be scared about.

So you mentioned about the issue with no IOMMU in the path. That's not technically true. Although it's certainly possible to not implement one. So you -- CXL devices are obliged to use ATS if they're accessing host memory anyway. Which is fine. And the problem with ATS is always you're saying, I've translated it. And the host believes you. Now, the specs were always written with the intent that it was perfectly permissible to put a checker on the path. And that's definitely an option. Whether anyone's done it in their host, I have absolutely no idea.

Yeah, so technically it's true. Like a CPU can add some kind of IOMMU to block CXL traffic. And only allow some addresses to be accessed by specific devices. So technically it's doable. But I don't think any of the CPU makers are actually looking into doing that. As far as I know. And as far as we can say here also.

If it is a security concern, it's one of those things that I know has been discussed in the past. It's perfectly doable. It requires some slightly exciting caching.

Yeah, it's not so much of a security concern as it is something we want to keep in mind. So it means that if we want to have access control, then it means we need to have access control in the device. And we need to be able to trust the device to enforce the access control. And it goes back to all the complexity. Like, you know, making a device secure is not that easy. It's not, hey, I just have like some controller that runs something. No, when hardware block inside your device can be attacking another hardware block.

