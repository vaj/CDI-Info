
Hello everyone, my name is Kapil Sethi. I work at Samsung Semiconductor, and the topic for the presentation is integrating composable memory systems into storage-intensive workloads. So, as you can see from the list here, many folks from different companies work on this. Today, Seema from Ampere, Ravi from Micron, and I will do the presentation.

Okay, so we'll go through, first of all, what the motivation and background for this work is, why we are doing this, and then we'll look at some of the results of composable memory systems, specifically CXL memory, on storage- and memory-intensive workloads like Redis or Apache Cassandra, or Apache Spark. Finally, we'll look at next steps and a call to action.

Okay, so when we started working on the evaluation of workloads using composable memory systems or CXL memory, we realized that there are different types of workloads, and they might fall into different categories. They could be compute-bound or memory-bound, and within memory-bound as well, they could be constrained by memory latency or memory bandwidth. Now, following the charter of CMS, we are focusing on two different aspects. One is native memory expansion, where our goal is to maximize performance per dollar. On the other side of the spectrum is a pooling solution, and there, the goal is to lower dollars per gigabyte.

So, having said that, in the presentation right now, we'll cover two different aspects, two types of workloads. One is online storage, and the other is data analytics. As you can see here, there are different workloads we are exploring, and you're going to hear about them in different presentations throughout the day.

Okay, so first of all, Redis on CXL devices. As an overview, what is Redis? A lot of us know it's a quick-access database, where data is stored in memory instead of your traditional SSDs or disks. Because the data is stored in memory, the performance depends on the memory capacity and memory latency. And what are the typical use cases of a Redis database? When you need quick-response data access: data caching, vector database, etc. Another challenge that we see with Redis databases is right-sizing the Redis cluster. One of the issues we hear from people who work on it is the problem of over-provisioning the memory, which often leads to memory stranding—where all the computes are being used, but there is memory left behind, stranded.

And we can use CMS solutions to solve these problems. So, we can have a situation where the Redis instances in a cluster can be shared with a memory appliance or shared memory across different Redis instances. This could help allocate memory on a per-need basis. When there is not enough demand, memory can be released to other rack-level applications. But before we move to pooling, we must take the first step. And the first step is memory expansion.

And we need to find out: Is CXL memory even suited for handling Redis queries? What is the performance impact? How does CXL memory compare to your native DIMM memory for Redis applications? So, we worked on it. We worked on assessing the performance impact of CXL memory for Redis. As you can see here, in the picture on the left side, we have one setup where Redis is running on CXL memory only. You have two 256-gigabyte CXL modules. On the other side, Redis is running on DRAM main memory only, which uses your native DIMM slots. Again, the capacity is the same, 512 gigabytes on both sides, and we want to see how the performance compares between these two setups. Now that we have established that baseline, let's look at the results.

Okay. So these are the initial results where we compare the latency, specifically the P99 latency (tail latency), and operations per second between Redis running on CXL and native DIMMs. The results are very promising, considering that a lot of optimization can be done further through software and improved hardware as well. So, we feel we are on the right track with this, and these results will only get better over time.

So, having said that, what are the next steps? What are we going to do? As I said, the results are promising from native expansion testing on Redis. The next step is to move it ahead: go to multi-node CMS pooling solution evaluation, and also do a TCO model evaluation from the business point of view. So, this was about Redis.

Now, let me pass the mic to Ravi, who's going to talk about Apache Cassandra.

Thank you, Kapil. Hi everyone. My name is Ravi Gummaluri. I'm part of system architecture for Micron. Today, I'm going to talk about Apache Cassandra workload analysis that we have done with respect to local DRAM versus CXL. How is the scaling happening, and what are the advantages we are seeing? How is the Cassandra workload performing when moved to CXL? So, we have some analysis. Given the time we have here, we probably won't be able to cover all of it. We are planning to publish a whitepaper with detailed analysis that will help you understand the workload better. Today, I'll just give you an overview and share the initial results we are seeing. But a whitepaper with detailed analysis is going to come out, which will be helpful for you.

Okay, just an overview of what Apache Cassandra is. Apache Cassandra is an open-source, distributed NoSQL database. It is built for scalability and fault tolerance. Some of the typical use cases are social media platforms, real-time data analytics, e-commerce, fraud detection, and risk management. Very popular ones include Twitter, Instagram, and Netflix, which all use Cassandra workloads—that is, the Cassandra database. When it comes to scalability and fault tolerance, scalability refers to the number of nodes you can add to the cluster to handle increased workload. That is the essence of scalability. However, for scalability, you need sufficient memory, high-performing SSDs, and a robust network link. For fault tolerance, data replication is necessary, which also requires more memory and capacity. So, for both scalability and fault tolerance, sufficient memory is essential—this is what we are talking about in the context of CXL.

Just a quick overview of the single-node architecture here. It's not completely calling out what Cassandra architecture is. We are trying to explain how the read and write operations happen in Cassandra, and how the flow works.  In the single-node setup, if you look at DRAM, the MemTables are actually sitting where you would call it a data cache. You also have a commit log for persistence reasons, and SSTables for increasing capacity or data sets. When you do a write, the first step is that it goes into the commit log, which allows you to recover the data. The commit log is stored inside the SSD. In DRAM, you have MemTables, and the write is also stored there.  For the read operations, it first checks in the cache, which is the MemTable. If the data is found there, you can retrieve it from there. If not, further calculations are needed to fetch it from the SSTables stored in the SSD. Periodically, these MemTables are flushed to the SSTables for persistence, since memory in DRAM is limited. You cannot cache every dataset inside your memory table, so SSTables store the complete dataset.

Some of the analysis that we did with CXL versus the local DRAM, the basic setup that we are trying to demonstrate here, is on the right-hand side—a basic DRAM. We have used a Cassandra client, and we used a tool called Cassandra stress test. The Cassandra client is sitting in a client’s environment, and we have a server that is connected. The client and server are connected with 100 gig Ethernet. We have local DRAM with eight channels and 64 GB RDIMMs connected to it, providing around 512 GB of capacity. Additionally, we have three 1 TB SSDs where the dataset resides for the commit logs and data access tables. When we run the Cassandra stress test, targeting only DRAM, we saw some analysis results here. When we run the same Cassandra client targeting the CXL memory, we get different results, which we will discuss. But as you can see here, the infrastructure we have shows that CXL has half the bandwidth of local DRAM, while the capacity is almost double. The latencies, as we know, are higher with CXL compared to local DRAM. So, essentially, we are targeting whether this workload is sensitive to latency, memory, or capacity. That is what we are trying to analyze here. The bandwidth is half, and the latency is high. The only variable we are experimenting with is capacity, leveraging the greater capacity provided by CXL.

Some of the initial results that we have seen here show that CXL is performing on par with DRAM at lower data sets. The KOPs are basically the same. When we increase the data set beyond the capacity of the local DRAM, where CXL can still fit in but DRAM cannot, that's when you see CXL KOPs outperform the local DRAM. With respect to latency, it is almost on par. There are various scenarios that we have considered: 2:1, 1:1, and 3:2 read-write ratios that we have analyzed. The outcome showed that bandwidth and latency are not significantly affecting the KOPs, which is the output. What we observed is that CXL is performing on par with local DRAM. In some cases, CXL's additional capacity is performing better than local DRAM. So, these are some of the initial analyses.

If we look at the summary of the analysis with a single node, the results are really promising. What we can infer is that Cassandra is insensitive to latency and bandwidth because we are running the workload with half the bandwidth and higher latency, yet the KOPs are performing as well as they do with local DRAM. The next analysis we are trying to conduct is whether we can scale this to multiple nodes, as multiple nodes require more capacity. That's where local DRAM might not perform as well. With the additional capacity provided by CXL, scaling will likely be much better, but the results need further analysis. These are the next steps. Additionally, we are exploring the TCO model that can integrate with CXL. If the second tier is sufficient for Cassandra workloads to move to CXL, we can introduce a TCO play around it. Therefore, analyzing the TCO model is also part of our next steps.

Having said that, I'll pass on to Seema, who will be talking about Apache Spark.

Good morning, everyone. I'm Seema Mehta at Ampere Computing and Technical Marketing. I'll be presenting on the Spark analysis here.

So, as we know, processor core counts have been increasing, and that's driving the memory capacity and memory bandwidth demands. And that's especially true for memory-intensive workloads like Spark and Presto, because they are the analytics engines for doing in-memory processing, caching operations, and shuffle operations. Traditional servers have a limited memory capacity, so if the data sets are more complex or the querying performances are more demanding, that can lead to more I/O activities and paging demands. This is where composable memory and memory solutions can help. There are, of course, two scenarios: native memory expansion and memory pooling.

So, the two use cases being discussed here are batch processing and real-time processing. In a distributed computing environment, where there could be uneven Spark tasks, it leads to memory stranding because the memory utilization by each node in a cluster varies from time to time. Therefore, because it varies, it can cause data spill or memory stranding. In addition, there is also the network-based data transfer overhead that can lead to data duplication, causing the memory footprint to grow. In the case of real-time processing, since Spark is a memory-bound workload, latency spikes can also force new node deployments, which further increases the TCO (total cost of operations). Hence, the goal here is to lower the TCO.

The existing work that focuses on memory expansion for Spark has already been discussed via memory tiering, and that has been shown to improve the performance speed-up by almost 2.5 to 2.6x versus simply using DRAM. However, memory stranding remains unaddressed. So, that's what the focus of my work here is going to be.

So the proposed solution is memory pooling for Spark in case of batch processing. Because batch processing is not so latency-sensitive, we are assuming it's relatively latency-insensitive versus real-time processing. What happens is that when you're pooling memory from different nodes into a combined pool, you're minimizing memory stranding, data spill, data transfer overhead, and data duplication. All these effects are getting minimized. In that sense, it would improve the TCO because there's no stranded memory now, or it's mitigated. When you implement a compressed CXL tier, meaning the data is being compressed over the CXL interconnect, that would further lower the TCO.

Some back-of-the-envelope calculations in two scenarios: without pooling and with pooling. So, when you have the near CPU socket memory, assuming 200k for the total memory cost in both cases—without pooling and with pooling—you have the poolable memory, again, at the same amount, 200k. But with the 20% CXL premium, let's say it's now 240k with pooling. However, because we are removing the stranded memory, or at least minimizing and mitigating it, we estimate that with pooling, the stranded memory could go down to as low as 0. With power absorption roughly about 60k and 40k in the two scenarios, the total cost comes out, and we observe almost 30% TCO savings at the higher end with pooling, which is pretty impressive. And again, as I mentioned, the TCO savings with CXL—and particularly with compressed CXL—are notable.

So the next steps here, and the call to action, would be to analyze the memory usage patterns, estimate the memory that can be pooled, design and test the reference architecture, perform TCO analysis for composable memory systems, conduct performance benchmarking for the compressed CXL tier, and then, the call to action is: we have written a white paper. Download that paper, download the TCO calculators, reference configurations, and provide feedback and collaborate to improve these reference configurations and TCO models. And, of course, join and contribute to the OCP CMS working group. The QR code to scan is shown here on the right-hand side.

Can she stay for one question?

So, Reddy is saying there is no time. Do you have any questions? OK.
