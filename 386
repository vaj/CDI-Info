
Hello, everyone. Thank you for attending the CXL Consortium's and overview of the CXL 3.x specification webinar. We'll begin the webinar in just a moment. Today's webinar will be led by Mahesh Natu from Intel. If you have any questions, please feel free to enter them into the question box, and we will address them during the Q&A. I will go ahead and hand it off to Mahesh to begin the webinar.

Hi, everyone. Good morning, good evening, wherever you are. Welcome to the CXL 3.x spec webinar. My name is Mahesh Natu. I have been with the CXL Consortium since the very beginning. I co-chaired the systems and software work group in the consortium, and we have come a long way from the early days of CXL. I'm also a senior principal engineer and director of platform architecture at Intel Corporation. So with that introduction, let's kick off the discussion.

And as I mentioned, feel free to add questions in the question box as we go on. We'll address the questions at the very end of the webinar. Okay, so here's a quick agenda that I have. Let's go over the industry trends and some of the backdrop behind CXL 3.x. The environment under which we were constructing CXL 3.x. It's key themes of the CXL 3.x feature set. By 3.x, I mean 3.0, 1, and 2. There's three versions of CXL 3 that are out there. Specs out there. We'll talk about feature progression as to how some of the features evolved. Many of the features that we see were introduced in 3.0. And then we built on top of that in 3.1 and 3.2. In addition, when we released 3.2, we also added some brand new features, right? We're just starting fresh. So we'll go over that as well. We'll touch upon compliance update, summary, and then Q&A. Okay, so let's dive in.

So some of the key themes that we're seeing, right, as the CXL Consortium started looking at beyond CXL 2.0. Obviously, I don't want to say that AI and ML applications and heterogeneous computing—where CPUs and GPUs and other XPUs are working together—is exploring. The way that CXL 3.x addressed that is by doubling the effective bandwidth and adding some enhancements to the caching protocol that would allow these entities to work together more efficiently. We also added support for larger fabric. So you can build a very large topology with lots of these compute elements, right, thrown together, and they can work as a single cohesive unit. The second thing we saw was a number of attempts—and actually, even proof of concepts and some successes—in disaggregating memory from the compute. There was just a lot of push for reducing the cost of stranded memory in large data centers. Where sometimes memory is overprovisioned. So a number of large CSPs and other customers were looking at separating memory from compute and sort of dynamically allocating the memory that's needed for a specific workload as the workload changes its characteristics. So what we've done in 3.x to respond to that is by standardizing the interface for managing pooled memory and shared memory. This allows these vendors to build such hardware and have a generic management, right, with standard capabilities that meet their use cases. We also saw that there were a number of instances where companies were deploying a low-cost memory option, like, for example, DDR5 is the latest and greatest technology, right, at this point for memory from JEDEC. But many of the vendors had DDR4 memory, right, that has been sort of utilized and they wanted to keep running it, right. So it, it was lower performance but also lower cost for them because they already sort of used that during their previous generations. So this allows—this, in this model, what they wanted to do was be able to have an effective software tiering mechanism that allows both memory, the DDR5 and the DDR4 memory, to be used effectively so that the applications don't suffer by types of performance. So what we've done, and I'll get into that in the 3.2 section, is by defining a mechanism for detecting hot pages. One can write generic software that can manage the memory and move pages quite efficiently between these two, or even more than two memory tiers. As the security expectations and requirements keep increasing, there's much greater demand for confidential computing. As various organizations are moving their workloads to cloud, they want assurance that the cloud service provider is not able to peek into their workload or into their secrets. They don't want that. They want to get assurance that that is the case. So there's a number of such technologies being built. What we did in CXL, starting with 3.4, is add support for what we call TSP. So that allows these workloads to be placed on CXL memory devices and allows CXL accelerators to participate in the confidential computing workloads. The other thing that also happened at the same time is that there were a number of other efforts, other efforts for coherent I.O. that were ongoing, and some were really reasonably far along. But I think the industry as a whole decided that having multiple efforts, all addressing the same problem, isn't really cost-effective. So I think the industry got together and then decided that let's focus all the energy on CXL for the coherent I.O. So the other efforts that are going on, CCIX, OpenCAPI, Gen-Z specifically, their assets and their work was submerged into CXL. And we'll see some of that we added to CXL that essentially originated from some of these standards. So a lot of work had happened there. They had made great progress. And so CXL decided to efficiently use some of that technology effectively. So that's the summary. So let's get into the details.

Quickly, the spec release timeline. We started back in March. March 2019 with the 1.0 release. Just a few months later, the consortium became officially incorporated. We released 1.1 with few changes and a compliance chapter. November 2020, you can see a really rapid movement because of the industry demand. 2.0 was released, highly successful. A lot of devices and components out there that support the CXL 2.2 spec today. In August 2022, we got to 3.0. Soon after that, 3.1 and probably 3.2. Based on the environment that we just talked about.

This one again shows the industry standard convergence we talked about. We had OpenCAPI, Gen-Z, and CCIX. They did a lot of good work, and all of that sort of is now flowing into CXL. And that shaped the CXL 3.x specifications to a great extent.

Okay, so let's talk about specific features that got into CXL. So CXL 3.0, a major benefit over 2.0 was really doubling the bandwidth. We switched to PCI 6.0 PHY. That means we got 64 GT/s transfer rate. Again, with PCI 6.0, we also moved to PAM 4.0 to sort of simplify the transition to doubling the bandwidth with the same clock. Again, there's other things that PCI did in terms of the forward error correction and CRC. That's CXL sort of leveraged. You can show the picture on the right side, right? If you look at the PCI 6.0 flit layout, it has CRC and forward error correction. And the CXL has two formats. One is the standard format that also carries forward the 6.0 forward error correction and also the CRC. And adds a two-word flit header that identifies what's inside the packet. But very similar to PCI 6.0 layout. We also have another layout that we call Latency Optimize. That allows the receiver to sort of...pull the data quickly and start processing it before the entire 250 bytes are available. So you essentially end up with sort of two chunks, or what we call two flit halves, that transfer data. So it essentially, in some applications where latency is a high amount, that format can be used. Okay. Obviously, backwards compatibility is essential to CXL success. So we continue to support the lower data rates. We have 8, 16, and 10-bit 64 GT/s. And again, the previous devices that are built to 2.0 and 1.1 continue to work with the 3.0, of course.

So let's get into the 3.x feature applications. Again, we're going to talk about features that essentially started...had a beginning in the 3.0 spec release. We enhanced a little bit in 3.1 and 3.2.

So we'll see that progression in many of these features. So the first amongst that is essentially the scale that a CXL system has. So in 1.1, we're looking at a single server. Maybe a few CPUs. Maybe a few CXL devices. All in what you would call a single node, or a coherent...running a single OS. That's where we started from. From that, CXL 2.0...added some pooling capabilities. So we expanded to maybe a rack level. So if you look at the picture on the right side, so in the beginning, we were at just a server. Then we got into that. And with some of the technologies like Gen Z, they were trying to go far beyond that. They had a solution for a much larger fabric. And as Gen Z and CXL started working together, some of the ideas were incorporated into CXL. Some of the use cases that Gen Z was able to address also made its way into CXL. So we essentially now have a much larger fabric that can span multiple racks and even entire node potential through a switch. And even a two-level switch hierarchy, so essentially with a leaf switch and a spine switch hierarchy. And maybe something like that.　So again, in terms of the scaling, as to how many nodes there can be in a single sort of CXL domain, it increases significantly when going from 1.1, 2.0 to 3.x. And within 3.x, there were improvements from 3.0 to 3.1 to 3.2. When we talk about that.

So this sort of shows a simple picture of a CXL fabric. So again, it's a nice cartoon, but it shows multiple CXL switches that have connected to each other through sort of a non-3D type structure. Lots of connections going from one switch to another switch. And that's for things like failover, and traffic balancing. And then each switch can be connected to a node that can either be a CXL host, CPU device, or even a PCI device. In many cases, as you know, that you can attach a PCI device in a CXL slot. And then essentially because it's the same type of slot for both of them. So 3.0 essentially enabled a non-3D architecture as shown here. In 3.1, we went even further by enabling larger fabrics, kind of what I showed you. There's a new concept that we introduced called port-based routing that allowed the requester, or the source, to essentially populate the information for routing, that allows for much larger fabrics. That came into 3.1. We also defined fabric-attached devices, where you have fabric, and you can essentially attach memory devices to it that are servicing requests from many, many hosts, in theory up to 4000 or something. Really large number of hosts. We also beefed up our fabric management APIs because such a large fabric requires very careful management and orchestration. And without standards to manage such a large fabric, it can get out of hand. So the fabric management API section in the spec was beefed up quite a bit in 3.1. So these large-size fabrics can be configured and operated efficiently.

The other big advantage that CXL 3.x brought in was enabling peer-to-peer communication. So as you know, peer-to-peer communication is pretty common in the PCIe environment. So with CXL 3.0, we enabled peer-to-peer communication between devices. So as shown in the picture here, you can have one of these devices, it could even be a PCI device, that's requesting access to memory on a CXL memory device to switch without going to the host. So that was introduced in CXL 3.0. It uses the PCIe unordered I/O protocol because it uses PCIe unordered I/O protocol, the requester, as I mentioned, can be a PCIe device as well. Just like the CXL, they work nicely together. And one of the key things that was added in 3.0 was the ability for the target device to manage coherency. What can happen is that, when a PCIe device, a requester, asks for a cache line from the memory device to actually go into the switch, it could happen that one of these hosts or CPUs may have cached it in this local cache. So the device needs to get the latest copy from the host or CPU. And that was enabled by this, what is called back invalidation protocol, an extension of CXL 3.0. So that allows the device to get the latest copy and return the latest data to the requesting device. Therefore, whether it gets the latest copy, there is no cache compensation. So that was a major advantage or benefit that 3.0 brought in. 3.1 went one step beyond and added peer-to-peer communication similarly to the switch, using CXL.mem Requestors 3.0 used PCIe unordered I/O. 3.1 essentially added CXL.mem Requestors, and responders going to the switch without going to the signal. So again, more efficient communication between CXL devices allows more efficient communication, more efficient performance, better latency in terms of accesses.

The other, really nice thing that CXL 3.x added was memory pooling. Technically, 2.0 defined some basic memory pooling concepts, but they had limited scalability. So 3.x went way beyond and allowed a lot more flexibility and a lot more scalability in terms of memory pooling. So what memory pooling is, it allows a host or CPU to dynamically expand or shrink its capacity to match workload. Some of the workloads have characteristics where, for some amount of time, they need a lot more pages, a lot more memory, and once the burst goes away, they don't need that much memory. So what happens without memory pooling is that all the nodes have to overprovision memory. They have to have the memory that's enough to handle the burst scenario. And during the other times, that memory is essentially wasted. That is what's called memory standard capacity, and that's really bad because memory is expensive. So wasting memory in a data center, I don't know, thousand, ten thousand, or even hundred thousand machines environment, so memory pooling avoids that by allowing the memory from one device to be allocated to, as you can see in the picture, Device D2 has some pages assigned to H1, Host 1, some pages assigned to H2, Host 2. And if Host 1 demands more pages, it's possible to take pages away from H2 and then give it to H1, pretty dynamically, pretty quickly. So 3.2 again defined standard OS to device interfaces for requesting more pages, accepting more pages, and also fabric manager to device interfaces that allow the reassignment of pages from one host. Again, without these standard interfaces, it's very difficult to build a system that's successful, a fabric manager that's shown here, now can use standard APIs to talk to the device to make this happen, very very efficiently. And there's some examples out there by open source that have been written to this standard. 3.1 went again one step beyond and then also attached, allowed fabric attached devices. These are again, like talked about, large fabrics with lots of devices, thousands of devices, potential devices, they can be serving lots of hosts, so need a lot more scalability than the simple configuration, so some of these were added in part of 3.1.

Again, really exciting feature! The other advantage, benefit that CXL 3.0 was memory sharing. Again, different between memory sharing and pooling is that in the sharing case, a memory page is shared by multiple hosts at the same time. So as shown in the picture here, device D1 has let's say two pages, S1 and S2. Both H1, Host 1, and Host 2, both are operating on S1. Host 2, and this other host, are also operating on S2. So they both have a shared copy. Allows them to do a much more efficient data exchange, and there's some software primitives that work really, really well. Software primitives work really well with shared memory. So again, this relies on some of the back invalidation options we talked about that allows the device D1 to make sure each of the hosts has the latest copy of the memory. And now the host actually it's confused or pulled out of sync. Again, really exciting feature! Again, requires a lot of software. I know some of the software work is happening in academia, work that's happening on enabling this. Again, this has a lot of promise and can change really, really how we write software in distributed systems. It's an exciting feature!

We can't really talk about anything these days without security. We're heavy on security. So here's the CXL answer. As I mentioned, as the workloads go to the cloud, the owner of the workload, or the customer wants to make sure that the data that is running in that virtual machine that they hosted on the cloud, cannot be tampered with. Cannot be leaked by anyone, including the CSP infrastructure itself. So they want to make sure that there's a cryptographic separation between trusted VM and the CSP infrastructure. Infrastructure includes things like the hypervisor itself, management software that the CSP may have. So they really want to make sure that data that's in the trusted VM is really protected, cryptographic. They also need support for memory devices and accelerators, devices for hosting memory and accelerators obviously for accelerating workloads. So we want to use all of those in the context of a trusted VM. Clearly, the data that's stored in the host doing use, meaning using computation, must remain encrypted, and there must be a way to verify that the system is set up correctly, right, to sort of meet the security promises. So again, has to be based on cryptographic. So all of these things right, we added to CXL in what we call CXL TSP, a trusted security protocol. So it allows someone to build again the industry term for this is TEE. Trusted execution environments that in a system that has CXL memory and CXL accelerators. So I show in the picture, so we have a TSP capable host that has some just regular VMs and a trusted VM. The, the trusted, the memory, the color code it shows the memory allocation, so the blue color shows the trusted VM and memory that's assigned to that. And there's a separation between that and cryptographic separation. Again, this happens on the host side, but CXL extends that trusted VM domain to memory device as well. So if you look at memory device here, it has again two sections. One section that's used by the VMs and the one section of memory that's sort of cordoned off for the use of the trusted VM. And that provides all the security that we just talked about between the two. The CXL link that transfers data supports encryption and integrity protection as well as replay for call CXL IDE that was introduced in CXL 2.0. So IDE stands for integrity and data encryption. Followed what was done on the PCI side. So this feature was in 2.0. What was added in 3.x was the whole TSP, how to keep the data protected while it's in use. Clearly, we talked about it. It allows some folks to migrate the sensitive workloads to clouds without really worrying about the data being leaking. It allows multiple parties to collaborate on a single problem without really sharing the data. So if I have a data set A and you have a data set B, I don't have to expose data set A to you. But someone can compute based on A and B together and come up with conclusions that's what this technology allows. There's also a number of compliance and sovereignty requirements that are coming up maybe from the customers, maybe from some organizations. Allows you to meet those and in general allows better protection from the applications and as well as actually. So again, this was a lot of work went into this. This is a very difficult thing to accomplish. But I think a number of folks in the consortium worked really really hard to sort of make it happen. Thank you for that.

So we build on top of IDE in 2.0. As I mentioned, 3.0 took the first step, adding TSP for simple memory devices. These devices rely on hosts for coherency management, but they don't really have their own coherency management. We had lots of these devices that are built in 2.0. A number of vendors have these devices, so it made sense to start with that as the first intercept. That's what we did in 3.0. Again, that was a big step forward. In 3.1, we built on top of that and extended that to cover accelerators, right? The ones that use again, CXL.mem only, but can manage coherency. So now, in 3.1, we have memory other accelerators that can now be part of the trusted VM domain, and these workers can benefit from that. 3.1 added some additional improvements to IDE. So there's some error information or positive message that we had that did not have IDE protection. That was addressed in 3.1 to complete the picture. This allows IDE or security protections to work completely, right, 100% right, in presence of some of these cases. And 3.1 too, obviously importantly, right? So all of these things are really not being useful, right, unless there's a compliance test, right? The specs can be complex, right, and we'll get into compliance a little bit later. But it's really a key part of the CXL specification. We have a good quality compliance test. So in 3.2, we introduced the compliance test for TSP. So this should help in between posts and devices and other components that are trying to intercept this feature, TSP.

Okay, so let's talk about the features that sort of progressed from 3.1 to 3.2. So let's talk about brand new features that made its way into 3.2.

So one of the major enhancements that was intercepted in 3.2 was CXL hot page monitoring, what we call CHMU. The primary use case was memory tiering. Before this, a number of companies had made some really good attempts at solving this problem, but all of them faced some common challenges. So before CHMU, when someone was trying to build a software care installation, they needed to trade off accuracy, which means how accurately they can track the hot pages, against performance overhead. If they wanted very high accuracy, they needed to spend more CPU cycles tracking hot pages, and they needed larger data structures in the main memory to track hot pages, which means bad for performance. And this was a really tough trade-off to me. But if they went for a really low performance overhead option, then they got terrible accuracy, and then the effectiveness of the tiering solution went down quite a bit. The other thing that was challenging is that since they were trying to measure the hot pages from the CPU standpoint, right, the measurements were polluted by cache hits. It was difficult to sort of separate out accesses that were satisfied by the CPU cache versus the ones that were not, and so the data was kind of somewhat polluted and hard to make sense of. Because these algorithms were CPU vendor-specific, and that made it difficult to sort of scale in a large data center environment. So what the approach we took with CHMU was that first of all, we started with simple memory devices and pooling memory devices as the starting point. That's what we targeted for the hot page trackers. The trackers are implemented in the memory device itself, right? So as shown in the picture here, each memory device has what I call CHMU hot page trackers. So the device that's connected to the host has two such CHMU instances, right? And the ones here, this one has two, and it's a pooling device. So it has two, one per every host. And this device has a single tracker. So these trackers are essentially data structures that figure out which pages are more frequently accessed. I'll explain that in the next slide. So because these are in the CXL memory device, it avoids the pollution of the cache. Right? You only track accesses that go to memory and not the ones that are satisfied by the CPU cache. So that solves the other problem. Because they're in this memory device, again, there's no host, the CPU is not really tracking. It's not spending cycles. There's no pitch-based record. There's no overhead of the system memory to keep track of these things. So that avoids performance issues. The interface is standard, so you can essentially build a generic OS-based solution for tiering that sort of works across multiple CPU vendors. And this allows the architecture allows multiple CHMU units, like I showed in the picture, so that gives software a little bit more flexibility. This is still sort of the emerging domain. A lot of exciting research is happening. So we wanted to provide enough flexibility for folks to do experiments and try out and optimize these algorithms. We allow counting at a different granularity as well. Again, more flexibility is better. But in the end, we just allow someone to improve the software tiering solution. It's more efficient, and that essentially means better performance and lower TCO and lower cost. Maybe low performance devices as a second tier, and hide all of that overhead latency overhead from the application.

Digging a little bit deep into that, I mentioned about the CHMU being highly configurable. So this allows software to make best use of these critical resources. There's not a lot of resources that the memory device can spend on tracking these, so software can configure the memory device. So software can optimize what it wants to see at a given time. So software can configure the specific DPA, or device address toties, that tracking happens. It's called a unit. A unit size is configured as software decides, but maybe it could be a megabyte for example. A unit the memory device will keep track of accesses, and in my opinion, is hard if it exceeds the number of accesses that software has configured. Doing what we call ‘epopulate’ is set up by software. So software can configure the device to say, "If you get more than 50 accesses during 100 milliseconds, or one second, that's my definition of a hot page, right?" And the device will follow that. And again, these things can be changed by software as part of the tuning, because different workloads, different environments, may need different granularity and different epochal lengths. So again, a lot of flexibility. You can essentially have tracking in multiple ranges that are not contiguous. So maybe software doesn't have resources to track hot pages for an entire device for a large device, but you can pick it up into separate some ranges and then track them at that level. A lot of flexibility. When the device decides a page is hot, it will add that to a circular structure called a hot list. The counters are not given to software, but the hot pages are exposed to software. And software can either poll for the hot list periodically, or it can ask the device to interrupt when the hot list like starts to become full and is going to overflow. So allow software to keep track of the hot pages effectively and efficiently, either polling or inducting. And then software can also decide here are the types of, I don't want to count. Let's say we talked about TSP earlier. So there are certain types of CXL requests that are generated by trusted VMs, and maybe software doesn't want to track those because of the security concerns. So software can say, "Hey, don't track those. Only track the ones that came from the regular VMs." So that flexibility is to, so again, a lot of work went into this. It took us about, I don't know, maybe nine months to work through all the details, the software model, and appreciate the effort by the consortium members in making this happen.

We also added some enhancements going with PCIe. This is a good example of how we were closing with other industry standards. This ECN MMPT management, message pass-through, was really built by PCIe on top of some of the CXL 2.0 constructs. They made special accommodations for us, but again, excellent collaboration with PCIe. It allows a standardized or space management of CXL as well as PCI devices, so everybody, see? Because someone can build a standard management software that works for PCIe devices as well as CXL and don't have to reinvent the wheel for CXL.

The other enhancement that was made, we talked about support for pooling in 3.X. And as the pooling devices become more commonplace, it becomes important to make sure that a pooling device that's shared by, let's say, 8 hosts, an error in the pooling device does not bring down all the 8 hosts. So this enhancement that we talked about here allows the device to specify which of the hosts is affected by the error. So the head ID and the LD ID field that are shown here, they can be used by the fabric manager to decide which of the hosts is affected by the error, and only bring down that host, keeping all of the hosts. So allows a more localized error handling. And if there is a uncorrectable or fatal error in a memory pooling device, the radius of that is reduced to maybe one host, and maybe a couple of hosts. So again, some of these things go hand in hand with enhancements that we talked about for memory pooling, but I think this intercepted maybe later than some of the other ones.

There are other enhancements that we did for POST package repair and the performance monitoring events. That allows better performance analytics for memory devices and also storage of the metadata bits. This allows us to optimize the metadata bits that a device stores based on the host needs. So then, I maintain the storage, again, I will not get into that in detail now. But the slides are available, and you can obviously look through that later.

Again, looking at the summary, we talked about most of these. So 3.2 primarily added some of the security compliance requirements. Again, this slide, I will skip in the interest of time.

This is the kit creating, so we did start official testing for 2.0 devices in December, just a couple of months ago. So we do host test events, so the members can bring in devices to these events, and then do interoperability testing and then get listed. So the current list is listed here, and I think last count we had like 48 devices. The snapshot below shows kind of what's out there, but I encourage you to go look at this link and figure out which devices are listed. So again, this goes hand in hand, this shows the solid support ecosystem has to see the specifications and some of the devices or vendors that are building devices to the spec, right? Again, really great to see some of the spec that has been done turning into reality, and folks able to build devices that interact with each other.

Okay, quickly summarizing, we talked about 3.2 that added a number of security enhancements, compliance enhancements, and a number of device enhancements. The memory device monitoring, management optimizations, including the hot page monitoring, other enhancements to the memory devices as well. A big thing was expanding TSP to address some of the, some of the ID protection, as well as support for accelerator devices, right, that use the HDM-DB device manage coherency protocol. And compliance chapter for TSP. Again, this is where we are, 3.2. We are, again, we are not stopping there. As we move further right, we are actually working on the next generation of CXL spec that again, the key that we are looking at is increasing the speed, again, to maybe 2x of what we have right now, and there are other features that are improvements to AI workloads or memory expansion, as well as reliability and security. Those will be our key focus areas for the next generation. Again, like I mentioned, 1.1 and 2.0 devices are available today. You can scan the code to see where the device ecosystem is, but like I mentioned, there is a large number of vendors and devices out there that are defined in a compliance test.

So, I think with that, let's go to Q&A.

Excellent, thank you. So now we will go ahead and dive into the Q&A. If you have any questions, please feel free to submit them into the questions box. So our first question for today's Q&A is: How can I tell the difference between a CXL 3.2 device, a CXL 3.1 device, and a CXL 3.0 device?

That is actually a quick question. If you look at the CXL specification, there is no register 'b' or anything that says 'I am a 3.2 device,' or '3.1 device,' or '3.0 device.' And that is on purpose. There is no such thing as a 3.2 device. When folks say a 3.0 device, they generally mean a device that operates at PCIe Gen 6 speeds. But other than that, pretty much all the other features that are seen by software are discoverable independently. You could discover, look at a device and say, 'Hey, does this device support CHMU or not?' And in theory, there is nothing that prevents a PCIe Gen 5 speed device, one that is returned to 2.0 spec, right, at that speed, from implementing the CHMU. Software doesn't really care. Software doesn't look at the CHMU capability and start using it, whether the device is running at Gen 5 speed or Gen 6 speed. So again, there is no such thing as... there is no way to differentiate between them because they are essentially one and the same thing. All the features that separate them can be enumerated separately independently, and software can make use of them without really knowing which spec version the device vendor was reading when the device was constructed.

Excellent. So our next question is: Is TSP compatible with other confidential computing technologies, like TDISP?

So, I think another good question. So TDISP is a PCIe-defined technology that allows, again, similar to TSP, trusted VMs to make use of the PCIe devices for computation and other work. So TSP was sort of loosely defined on top of, similar to TLS, which has a lot of similar concepts and similar constructs. Of course, the CSF protocol is quite different from PCIe, especially the dot cache and dot command aspects. So TSP had to do some additional work to kind of meet some of the security requirements that TDISP met for PCIe. So, but yeah, they are conceptually very similar. There are other technologies from different vendors, like CPU vendors, that do confidential computing. I think we have participation from multiple vendors in the consortium, so I believe those are also compatible.

Perfect. Our next question is: What are the benefits of OS-based software tiering over application-based tiering?

So, when the system has different memory classes, one that is highly performant and one maybe not so, there are different ways to sort of optimize the usage of the page, right? So obviously, you want to make sure your hard pages, frequently accessed pages are in the higher performance memory, and it can be done at either, at an OS level or at an application level. Generally, the OS level approach is better because it's sort of done once. Benefits all the applications. You don't need to redo your application, you don't need to recompile applications, so have this work done in every single application. So that approach is generally better. Scales better in terms of the enabling or ecosystem usage. So I think that's really why I think CHMU, our goal was to enable improve the OS-based tiering technologies. Of course, right, it's not CHMU is not limited, right? If your environment requires application-based hard page monitoring, it can definitely be because of CHMU. But we wanted to make sure that the standard interface that CHMU defines allows a pure OS-based memory tiering solution.

Perfect. For our next question: Will enabling TSP have any performance impacts?

So, we had done our best to minimize the impact of TSP on performance. So, if you look at the IDE protocol, in order to encrypt the data, in order to send the integrity, and in order to process it, some additional work has to be done on both ends. It may have a small performance cost, but we've done our best to minimize the performance cost in terms of the work that the memory device has to do for servicing the request. I think it's, the tax is pretty small. We generally accept in the industry that adding security is not free. There will be some paid off, some performance indications, and the industry tries as a whole to minimize the performance impact of the security, and that's exactly what we've done.

Perfect. Our next question: could you answer whether cache coherency is possible in TSP between the host memory and device memory using CXL?

So, the cache coherency is possible. So there's two ways to sort of manage the cache coherency. One was the traditional CXL cache approach that was defined in the 2.0 spec. The device has its own memory that is cache coherent with the host. The device can use CXL cache to manage the cache coherency. Or in the 3.0, we introduce back invalidation concept, right, that goes on the CXL mem channel that can be used by the device to manage the coherency as well. The CXL spec allows devices that use the back invalidation based coherency to be supported. At this point, we don't have support for devices that use the CXL cache, but you can use the CXL mem channel in the back invalidation right feature to maintain coherency between the device and the host and still support TSP.

Excellent. Um, our next question: since a hot page is a function of the host/VM and memory pages, if it is on the memory that is shared, would it create a deadlock situation?

Okay, I think maybe you're asking about the use of CHMU in case of hot pages, in case of shared pages, right? So shared memory is really special, right? You can't use shared memory as just like regular memory, so care must be taken when using shared memory. And I do not believe, even want to use shared memory with tiered at the same time, right? It's just in a shared memory case, there's a memory device that has the shared page, has the memory location that is shared by multiple hosts, and they're both going to operate directly on that. Don't expect it to be to be tiered at the same time. Okay, if I didn't get the question, please feel free to email us later and clarify the question.

Absolutely, I think we have time for one more question. Um, so could you answer how does CHMU track coherency among hosts and devices?

So, CHMU doesn't actually track coherency. CHMU is, uh, is placed in this memory device, and it's monitoring the CXL.mem accesses that the device sees. These are memory requests that the device sees, and every time the device sees a read and write request to a certain page or certain unit, it's going to by increment account, right? So the currency doesn't actually come into the into the interface here because when the device sees the request, it's already like, has gone through the caches, has already coherence is already taken care of by by that.

Great! Um, well, that was the last question that we had time for today, so thank you again, Mahesh, for hosting the webinar. Um, the webinar recording will be made available on the CXL Consortium YouTube channel, and the slides will be available to download on our website. Thank you again for everyone for attending and have a great day! Thank you, everyone!
