YouTube:https://youtu.be/2EEXLeajOXI?si=ewcD8fQdKdKPKSz8
Text:
Hi there, I'm Jack Gidding. I'm the CEO of a company called STAC. We work in the financial industry to help technology firms and end users understand technology. 

Our focus is really improving the efficiency and effectiveness of the technology discovery process for firms in the financial industry. And we do this because finance organizations really need sophisticated technology. The technology discovery and evaluation is a slow and very, very expensive process, and that hurts both buyers and sellers. So, through STAC, we can help all the parties come together and gain an understanding of how things work and shorten the process.

We do that through the process that we have for engaging the community and building industry-wide proof of concepts using the STAC tools, the test harnesses, which give us a standardized assessment methodology for testing technology solutions. And then we have our community, who comes together at STAC events, which is where a lot of substantive dialogue happens in the industry. Now, this drives results for the end-user firms. It helps them reduce the discovery time and the cost for them in terms of evaluation of technology. It helps them understand what technology is out there for vendors and make better technology decisions. And it helps them get better solutions from technology vendors. For the tech vendors that participate in our community, the important part is that this helps with faster sales cycles. If they have results and can communicate those to customers, it helps them get in the door faster. But these tools and the process also give them better market insight and help enhance and expand their markets.

The main way that STAC engages all of these parties is through an organization that we call the STAC Benchmark Council. The Benchmark Council was founded in 2007, and it consists of financial firms, the end users in the community, and technology ventures. It establishes standard technology benchmarks that are based on finance workloads, and it progresses research agendas that are based upon industry priorities. Now, through the Council, we discuss technical challenges that are there in working groups and special interest groups, well beyond the benchmarks that we have as part of the Council. Now, the benchmarks are built and defined by a collaboration of STAC end-users and technology vendors, but ultimately, at the end of the day, the end-user firms are the ones who set the requirements and make the priority calls on the benchmarks. And the benchmarks provide a standardized way of evaluating technology solutions of any kinds of technologies, whether those are single-box solutions, multi-box solutions, cloud solutions, or everything on a chip. The benchmarks are set up so they can measure any kind of technology.

You know the Council has about 500 end-user firms, so these consist of financial organizations and business application vendors. You'll see on this list a number of the big ones that you would expect: investment banks, exchanges, asset managers. You'll also see many up-and-coming hedge funds, quantitative and prop trading firms, as well as technology applications that facilitate the trading process. So, there will be about 500 different end-user firms that are on that Council.

There are also 75 technology vendors participating as part of this organization. Below are many of the big ones that you would expect, such as Microsoft, Google, AWS, AMD, Intel, NVIDIA, etc. On the left, you will see networks, artificial intelligence vendors; you see storage, memory, network vendors. So, we have quite a collection here, and everybody comes together to collaborate as part of the overall council process in defining benchmarks and building our community.

The council works in a number of different domains as part of our process, and you'll see that there are two different categories here: both historical and real-time. The things that are in historical is where performance is important in terms of getting access to the data and doing calculations, computations, and utilizing that data, but not necessarily in an ultra-low latency fashion. So, STAC M3 tests enterprise tick analytics; A3 tests strategy backtesting; A2 tests risk computation; and STAC ML tests our large language models and ML inference. Actually, from this slide, we have a new one in here: it's called STAC AI, which is the large language model testing. And on the right side is the real-time, what you consider ultra-low latency. So, feed handling, data distribution, trade execution, real-time streaming analytics, as well as network IO. And throughout this process, we build test harnesses from the benchmark specs for each of these domains that enable people to test this and get insight in terms of the technology solutions that they have.

Now, STAC produces, as part of that discovery process, STAC reports. And so, you'll see a number of reports here that we've produced in one of these domains, STAC A2, and that's the risk computation domain. And vendors continually come in, use our test harnesses, gain that insight, and then want public audits of their technology solutions. We've published technology reports. And these are independent, rigorous, and respected in the industry. They help establish those value propositions that vendors want to convey about their products or their architectural decisions. And these reports help get them onto the customer shortlist. So, once customers can look and see these reports, they can see how things were implemented, see the test results, and get very excited about talking to vendors.

Now, one of the reports that we recently did is actually one that would be interesting to this group. We did a benchmark test with Liquid Markets Solutions, their 10G and 25G UberNet card. And this was actually the first CXL system under test, or SUT, that we've tested. This was tested with STAC N1, which is our network I.O. tests. And so, in our results and in our discussions, we detail all the parts of the technology solution that were tested. And you can see that the URL there will actually give you access to the reports that were published as part of this.

And then, we can see the results that they came out with. They had very good results for both their 10G card as well as their 25G card, comparing to enterprise-class CPUs.

Now, they use the STAC N1 test harness. And these test harnesses, in addition to all the other domains—in addition to STAC N1—are actually community-sourced amongst the benchmark council. So, firms, both end-user and technology firms, utilize these test harnesses to test their technology. They can use those internally in an organization and have no obligation to disclose those results. But, these tools help their engineering groups understand the requirements of the financial services market. And for technology vendors who use the tools, if they want to generate and have public results, they can engage STAC for an audit of their system, which is where we come in and we run a test. We gather all the details and document all the details of how things are configured, how the system is set up, and every piece of technology that is involved in the technical STAC. Now, vendors can also publish an audit of results into our STAC vault if they want to have those disclosed only to council members under NDA. And then, our community can collect those. Our community can contribute their own implementations and enable customers and partners to participate.

Now our community comes together at the STAC events, and these are where you can network with the highest quality attendees. We regularly have CTOs, CIOs, heads of architecture, heads of technology development, as well as people throughout the implementation STAC that come. And this is a great opportunity for technology vendors to come and speak or exhibit at the events and really establish mindshare for their firm and their technology. For those firms that do decide to do that—speak or exhibit—they will be able to generate leads and have responses that they can follow up on. Now, we currently have two summits per year in New York, Chicago, and London. We also do Asia. This year, we've also started a new event called AI STAC, and this is an event that is specific to artificial intelligence, deep learning, machine learning, gen AI, and the technology STACs that are used to drive those technologies. So this year, we're expanding beyond New York in that, and we also have an event called STAC Builder Day, which is tutorials and vendor-led training sessions that are targeted for implementers of technology STACs. So it's a way for vendors to... to help people understand more about their technology and build a fan base.

So, these are the dates for the upcoming fall STAC events. STAC summits are aimed at trading technologists involved in the trading process. AI STAC events are aimed at people building technology stacks to drive deep learning, machine learning, and generative AI. STAC Builder Day is meant for training sessions to help people understand and learn how to implement technology. The STAC summits that are coming up in New York are ones where we're specifically building out topics that I think would be very interesting to this group in terms of how data centers are evolving to meet the needs of technology providers as technology changes. We call it the data center of the future. We're also building topics around memory fabrics. So, we'd love to talk to you if you're interested in participating in those discussions.

And last, I want to sort of bring this back to a really interesting quote that came from a person who's both on the technology side and on the end-user side. And in here, he just talks about how STAC has built a very important company that's important to both software and hardware providers, but especially to the end users who have to deal with technology day-to-day and make some key decisions on that, and why STAC is important in playing in that process. So, with that, thank you, and I'd love to help. Please don't hesitate to reach out to me, and I'd love to talk more about it.
